[
  {
    "objectID": "labs/lab_1/lab1.html",
    "href": "labs/lab_1/lab1.html",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the California Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n\n\n\nApply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders\n\n\n\n\nSubmit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/labs/lab_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Labs” menu."
  },
  {
    "objectID": "labs/lab_1/lab1.html#scenario",
    "href": "labs/lab_1/lab1.html#scenario",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the California Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues."
  },
  {
    "objectID": "labs/lab_1/lab1.html#learning-objectives",
    "href": "labs/lab_1/lab1.html#learning-objectives",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Apply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders"
  },
  {
    "objectID": "labs/lab_1/lab1.html#submission-instructions",
    "href": "labs/lab_1/lab1.html#submission-instructions",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Submit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/labs/lab_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Labs” menu."
  },
  {
    "objectID": "labs/lab_1/lab1.html#data-retrieval",
    "href": "labs/lab_1/lab1.html#data-retrieval",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.1 Data Retrieval",
    "text": "2.1 Data Retrieval\nYour Task: Use get_acs() to retrieve county-level data for your chosen state.\nRequirements: - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)\n- Year: 2022 - Survey: acs5 - Output format: wide\nHint: Remember to give your variables descriptive names using the variables = c(name = \"code\") syntax.\n\n# Write your get_acs() code here\ncounty_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    median_income = \"B19013_001\",\n    total_population = \"B01003_001\"\n  ),\n  state = my_state,\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n)\n\n# Clean the county names to remove state name and \"County\" \ncounty_data &lt;- county_data %&gt;%\n  mutate(\n    NAME = str_remove(NAME, \" County\"),\n    NAME = str_remove(NAME, \", California\")\n  )\n\n# Hint: use mutate() with str_remove()\n\n# Display the first few rows\nhead(county_data)\n\n# A tibble: 6 × 6\n  GEOID NAME   median_incomeE median_incomeM total_populationE total_populationM\n  &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt;          &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n1 06001 Alame…         122488           1231           1663823                NA\n2 06003 Alpine         101125          17442              1515               206\n3 06005 Amador          74853           6048             40577                NA\n4 06007 Butte           66085           2261            213605                NA\n5 06009 Calav…          77526           3875             45674                NA\n6 06011 Colusa          69619           5745             21811                NA"
  },
  {
    "objectID": "labs/lab_1/lab1.html#data-quality-assessment",
    "href": "labs/lab_1/lab1.html#data-quality-assessment",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.2 Data Quality Assessment",
    "text": "2.2 Data Quality Assessment\nYour Task: Calculate margin of error percentages and create reliability categories.\nRequirements: - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories: - High Confidence: MOE &lt; 5% - Moderate Confidence: MOE 5-10%\n- Low Confidence: MOE &gt; 10% - Create a flag for unreliable estimates (MOE &gt; 10%)\nHint: Use mutate() with case_when() for the categories.\n\n# Calculate MOE percentage and reliability categories using mutate()\nincome_reliability &lt;- county_data %&gt;%\n  mutate(\n    income_moe_pct = (median_incomeM / median_incomeE) * 100,\n\n    income_reliability = case_when(\n      income_moe_pct &lt; 5                     ~ \"High Confidence\",\n      income_moe_pct &gt;= 5 & income_moe_pct &lt;= 10 ~ \"Moderate Confidence\",\n      income_moe_pct &gt; 10                    ~ \"Low Confidence\"\n    ),\n\n    unreliable_income = income_moe_pct &gt; 10\n  )\n\n# Create a summary showing count of counties in each reliability category\nincome_reliability_summary &lt;- income_reliability %&gt;%\n  count(income_reliability) %&gt;%\n  mutate(\n    percent = (n / sum(n)) * 100\n  )\n\n# Hint: use count() and mutate() to add percentages"
  },
  {
    "objectID": "labs/lab_1/lab1.html#high-uncertainty-counties",
    "href": "labs/lab_1/lab1.html#high-uncertainty-counties",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.3 High Uncertainty Counties",
    "text": "2.3 High Uncertainty Counties\nYour Task: Identify the 5 counties with the highest MOE percentages.\nRequirements: - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using kable()\nHint: Use arrange(), slice(), and select() functions.\n\n# Create table of top 5 counties by MOE percentage\ntop5_high_uncertainty &lt;- income_reliability %&gt;%\n  arrange(desc(income_moe_pct)) %&gt;%\n  slice(1:5) %&gt;%\n  select(\n    county = NAME,\n    median_income = median_incomeE,\n    margin_of_error = median_incomeM,\n    moe_percent = income_moe_pct,\n    reliability = income_reliability\n  ) %&gt;%\n  mutate(\n    median_income = scales::dollar(median_income, accuracy = 1),\n    margin_of_error = scales::dollar(margin_of_error, accuracy = 1),\n    moe_percent = round(moe_percent, 2)\n  )\n\n# Format as table with kable() - include appropriate column names and caption\ntop5_high_uncertainty %&gt;%\n  kable(\n    col.names = c(\"County\", \"Median Household Income\", \"Margin of Error\", \"MOE (%)\", \"Reliability Category\"),\n    caption = \"Top 5 California Counties with the Highest Median Income MOE Percentages (ACS 2022 5-year)\"\n  )\n\n\nTop 5 California Counties with the Highest Median Income MOE Percentages (ACS 2022 5-year)\n\n\n\n\n\n\n\n\n\nCounty\nMedian Household Income\nMargin of Error\nMOE (%)\nReliability Category\n\n\n\n\nMono\n$82,038\n$15,388\n18.76\nLow Confidence\n\n\nAlpine\n$101,125\n$17,442\n17.25\nLow Confidence\n\n\nSierra\n$61,108\n$9,237\n15.12\nLow Confidence\n\n\nTrinity\n$47,317\n$5,890\n12.45\nLow Confidence\n\n\nPlumas\n$67,885\n$7,772\n11.45\nLow Confidence\n\n\n\n\n\nData Quality Commentary:\nCounties with high income margin of error percentages are more likely to be poorly represented because the underlying estimates are more uncertain. These counties are often rural or have highly variable income distributions, which can reduce survey sample sizes and increase estimation error. As a result, algorithms using this data may misclassify economic conditions."
  },
  {
    "objectID": "labs/lab_1/lab1.html#focus-area-selection",
    "href": "labs/lab_1/lab1.html#focus-area-selection",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.1 Focus Area Selection",
    "text": "3.1 Focus Area Selection\nYour Task: Select 2-3 counties from your reliability analysis for detailed tract-level study.\nStrategy: Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n# Use filter() to select 2-3 counties from your county_reliability data\nselected_counties &lt;- income_reliability %&gt;%\n  filter(income_reliability %in% c(\"High Confidence\", \"Moderate Confidence\", \"Low Confidence\")) %&gt;%\n  group_by(income_reliability) %&gt;%\n  slice_max(income_moe_pct, n = 1) %&gt;%\n  ungroup() %&gt;%\n\n# Store the selected counties in a variable called selected_counties\nselect(\n    county = NAME,\n    median_income = median_incomeE,\n    moe_percent = income_moe_pct,\n    reliability_category = income_reliability\n  )\n\n# Display the selected counties with their key characteristics\nselected_counties\n\n# A tibble: 3 × 4\n  county    median_income moe_percent reliability_category\n  &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;               \n1 Calaveras         77526        5.00 High Confidence     \n2 Mono              82038       18.8  Low Confidence      \n3 Modoc             54962        9.80 Moderate Confidence \n\n# Show: county name, median income, MOE percentage, reliability category\n\nComment on the output: The selected counties are different in data reliability. High-confidence counties show relatively low income uncertainty and low-confidence counties have higher MOE percentages. This contrast shows how data quality can vary significantly across regions when applying income based algorithms uniformly across all counties."
  },
  {
    "objectID": "labs/lab_1/lab1.html#tract-level-demographics",
    "href": "labs/lab_1/lab1.html#tract-level-demographics",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.2 Tract-Level Demographics",
    "text": "3.2 Tract-Level Demographics\nYour Task: Get demographic data for census tracts in your selected counties.\nRequirements: - Geography: tract level - Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001) - Use the same state and year as before - Output format: wide - Challenge: You’ll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n# Define your race/ethnicity variables with descriptive names\nrace_vars &lt;- c(\n  total_pop = \"B03002_001\",\n  white_alone = \"B03002_003\",\n  black_alone = \"B03002_004\",\n  hispanic_latino = \"B03002_012\"\n)\n# Use get_acs() to retrieve tract-level data\nselected_counties &lt;- income_reliability %&gt;%\n  filter(income_reliability %in% c(\"High Confidence\", \"Moderate Confidence\", \"Low Confidence\")) %&gt;%\n  group_by(income_reliability) %&gt;%\n  slice_max(income_moe_pct, n = 1) %&gt;%\n  ungroup() %&gt;%\n  select(\n    GEOID,                     # ← keep this!\n    county = NAME,\n    median_income = median_incomeE,\n    moe_percent = income_moe_pct,\n    reliability_category = income_reliability\n  )\ncounty_codes &lt;- selected_counties %&gt;%\n  mutate(county_code = str_sub(GEOID, 3, 5)) %&gt;%\n  pull(county_code)\n# Hint: You may need to specify county codes in the county parameter\ntract_data &lt;- get_acs(\n  geography = \"tract\",\n  variables = c(\n    total_population = \"B03002_001\",\n    white_alone = \"B03002_003\",\n    black_alone = \"B03002_004\",\n    hispanic_latino = \"B03002_012\"\n  ),\n  state = my_state,\n  county = county_codes,\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n)\n\n# Calculate percentage of each group using mutate()\ntract_data &lt;- tract_data %&gt;%\n  mutate(\n    pct_white = (white_aloneE / total_populationE) * 100,\n    pct_black = (black_aloneE / total_populationE) * 100,\n    pct_hispanic = (hispanic_latinoE / total_populationE) * 100\n  )\n\n# Create percentages for white, Black, and Hispanic populations\ntract_data &lt;- tract_data %&gt;%\n  mutate(\n    county_fips = str_sub(GEOID, 3, 5),\n    tract_code = str_sub(GEOID, 6, 11),\n    county_name = str_extract(NAME, \"^[^,]+\")  \n  )\n\n# Add readable tract and county name columns using str_extract() or similar\ntract_data %&gt;%\n  select(county_name, tract_code, total_populationE, pct_white, pct_black, pct_hispanic) %&gt;%\n  head()\n\n# A tibble: 6 × 6\n  county_name      tract_code total_populationE pct_white pct_black pct_hispanic\n  &lt;chr&gt;            &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 Census Tract 1.… 000121                  4326      83.1    0              8.30\n2 Census Tract 1.… 000122                  3297      86.7    1.15           6.28\n3 Census Tract 1.… 000123                  2940      67.9    4.05          23.8 \n4 Census Tract 1.… 000124                  2152      77.5    0             19.3 \n5 Census Tract 2.… 000220                  6271      67.2    0.0159        21.4 \n6 Census Tract 2.… 000221                  6691      82.5    0             12.9"
  },
  {
    "objectID": "labs/lab_1/lab1.html#demographic-analysis",
    "href": "labs/lab_1/lab1.html#demographic-analysis",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.3 Demographic Analysis",
    "text": "3.3 Demographic Analysis\nYour Task: Analyze the demographic patterns in your selected areas.\n\n# Find the tract with the highest percentage of Hispanic/Latino residents\ntop_hispanic_tract &lt;- tract_data %&gt;%\n  arrange(desc(pct_hispanic)) %&gt;%\n  slice(1) %&gt;%\n  select(NAME, GEOID, county_fips, tract_code, total_populationE, pct_white, pct_black, pct_hispanic)\n# Hint: use arrange() and slice() to get the top tract\ntop_hispanic_tract %&gt;%\n  kable(\n    col.names = c(\"Tract Name\", \"GEOID\", \"County FIPS\", \"Tract Code\", \"Total Pop\", \"% White\", \"% Black\", \"% Hispanic/Latino\"),\n    caption = \"Tract with the Highest Percentage of Hispanic/Latino Residents (Selected Counties)\"\n  )\n\n\nTract with the Highest Percentage of Hispanic/Latino Residents (Selected Counties)\n\n\n\n\n\n\n\n\n\n\n\n\nTract Name\nGEOID\nCounty FIPS\nTract Code\nTotal Pop\n% White\n% Black\n% Hispanic/Latino\n\n\n\n\nCensus Tract 2.01; Mono County; California\n06051000201\n051\n000201\n3213\n63.99004\n0\n33.70682\n\n\n\n\n# Calculate average demographics by county using group_by() and summarize()\ncounty_demographics_summary &lt;- tract_data %&gt;%\n  group_by(county_fips) %&gt;%\n  summarize(\n    n_tracts = n(),\n    avg_pct_white = mean(pct_white, na.rm = TRUE),\n    avg_pct_black = mean(pct_black, na.rm = TRUE),\n    avg_pct_hispanic = mean(pct_hispanic, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(avg_pct_hispanic)) %&gt;%\n  mutate(\n    avg_pct_white = round(avg_pct_white, 2),\n    avg_pct_black = round(avg_pct_black, 2),\n    avg_pct_hispanic = round(avg_pct_hispanic, 2)\n  )\n# Show: number of tracts, average percentage for each racial/ethnic group\ncounty_demographics_summary %&gt;%\n  kable(\n    col.names = c(\n      \"County FIPS\",\n      \"Number of Tracts\",\n      \"Avg % White\",\n      \"Avg % Black\",\n      \"Avg % Hispanic/Latino\"\n    ),\n    caption = \"Average Tract Demographics by County (Selected Counties)\"\n  )\n\n\nAverage Tract Demographics by County (Selected Counties)\n\n\n\n\n\n\n\n\n\nCounty FIPS\nNumber of Tracts\nAvg % White\nAvg % Black\nAvg % Hispanic/Latino\n\n\n\n\n051\n4\n64.14\n0.23\n27.82\n\n\n049\n4\n76.57\n1.43\n15.06\n\n\n009\n14\n80.98\n0.93\n11.60\n\n\n\n\n# Create a nicely formatted table of your results using kable()"
  },
  {
    "objectID": "labs/lab_1/lab1.html#moe-analysis-for-demographic-variables",
    "href": "labs/lab_1/lab1.html#moe-analysis-for-demographic-variables",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "4.1 MOE Analysis for Demographic Variables",
    "text": "4.1 MOE Analysis for Demographic Variables\nYour Task: Examine margins of error for demographic variables to see if some communities have less reliable data.\nRequirements: - Calculate MOE percentages for each demographic variable - Flag tracts where any demographic variable has MOE &gt; 15% - Create summary statistics\n\n# Calculate MOE percentages for white, Black, and Hispanic variables\ntract_data &lt;- tract_data %&gt;%\n  mutate(\n    white_moe_pct = (white_aloneM / white_aloneE) * 100,\n    black_moe_pct = (black_aloneM / black_aloneE) * 100,\n    hispanic_moe_pct = (hispanic_latinoM / hispanic_latinoE) * 100\n  )\n# Hint: use the same formula as before (margin/estimate * 100)\n\n# Create a flag for tracts with high MOE on any demographic variable\ntract_data &lt;- tract_data %&gt;%\n  mutate(\n    high_demo_moe = ifelse(\n      white_moe_pct &gt; 15 | black_moe_pct &gt; 15 | hispanic_moe_pct &gt; 15,\n      TRUE,\n      FALSE\n    )\n  )\n# Use logical operators (| for OR) in an ifelse() statement\n\n# Create summary statistics showing how many tracts have data quality issues\ndemo_moe_summary &lt;- tract_data %&gt;%\n  summarize(\n    total_tracts = n(),\n    tracts_high_moe = sum(high_demo_moe, na.rm = TRUE),\n    percent_high_moe = (tracts_high_moe / total_tracts) * 100\n  )"
  },
  {
    "objectID": "labs/lab_1/lab1.html#pattern-analysis",
    "href": "labs/lab_1/lab1.html#pattern-analysis",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "4.2 Pattern Analysis",
    "text": "4.2 Pattern Analysis\nYour Task: Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n# Group tracts by whether they have high MOE issues\npattern_summary &lt;- tract_data %&gt;%\n  group_by(high_demo_moe) %&gt;%\n \n# Calculate average characteristics for each group:\n   summarize(\n    number_of_tracts = n(),\n    avg_total_population = mean(total_populationE, na.rm = TRUE),\n    avg_pct_white = mean(pct_white, na.rm = TRUE),\n    avg_pct_black = mean(pct_black, na.rm = TRUE),\n    avg_pct_hispanic = mean(pct_hispanic, na.rm = TRUE)\n  ) %&gt;%\n\n\n# - population size, demographic percentages\n mutate(\n    avg_total_population = round(avg_total_population, 0),\n    avg_pct_white = round(avg_pct_white, 2),\n    avg_pct_black = round(avg_pct_black, 2),\n    avg_pct_hispanic = round(avg_pct_hispanic, 2)\n  )\n# Use group_by() and summarize() to create this comparison\n# Create a professional table showing the patterns\npattern_summary %&gt;%\n  kable(\n    col.names = c(\n      \"High MOE Issue\",\n      \"Number of Tracts\",\n      \"Avg Total Population\",\n      \"Avg % White\",\n      \"Avg % Black\",\n      \"Avg % Hispanic/Latino\"\n    ),\n    caption = \"Comparison of Tracts With and Without High Demographic MOE Issues\"\n  )\n\n\nComparison of Tracts With and Without High Demographic MOE Issues\n\n\n\n\n\n\n\n\n\n\nHigh MOE Issue\nNumber of Tracts\nAvg Total Population\nAvg % White\nAvg % Black\nAvg % Hispanic/Latino\n\n\n\n\nTRUE\n22\n3070\n77.12\n0.89\n15.18\n\n\n\n\n\nPattern Analysis: The results suggest that demographic data quality issues are not randomly distributed across tracts. Tracts with high demographic MOE tend to have smaller average populations and differ in racial and ethnic composition compared to tracts with more reliable data. These patterns likely reflect lower survey sample sizes and higher population variability in certain communities, which increases uncertainty in ACS estimates."
  },
  {
    "objectID": "labs/lab_1/lab1.html#analysis-integration-and-professional-summary",
    "href": "labs/lab_1/lab1.html#analysis-integration-and-professional-summary",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "5.1 Analysis Integration and Professional Summary",
    "text": "5.1 Analysis Integration and Professional Summary\nYour Task: Write an executive summary that integrates findings from all four analyses.\nExecutive Summary Requirements: 1. Overall Pattern Identification: Counties and census tracts with smaller populations and uneven demographic distributions tend to exhibit higher margins of error, particularly for income and race/ethnicity variables. At the tract level, demographic MOE issues were widespread across the selected counties, showing that uncertainty is concentrated in specific types of communities. 2. Equity Assessment: Communities most vulnerable to algorithmic bias are those with less reliable demographic and income estimates, especially smaller-population tracts and areas with minority populations represented by relatively small counts. Because algorithmic decision-making systems often rely on these variables to allocate resources, it increases the risk of misclassification. 3. Root Cause Analysis: The primary drivers of data quality issues are structural features of survey-based data collection, including limited sample sizes, population sparsity, and high variability within small geographic units. 4. Strategic Recommendations: To mitigate these risks, departments should incorporate data quality metrics, such as margins of error, directly into analytic rather than relying solely on point estimates.Also, decision making systems should apply caution thresholds in high-uncertainty areas\nExecutive Summary:\nCounties and census tracts with smaller populations and uneven demographic distributions tend to exhibit higher margins of error, particularly for income and race and ethnicity variables. At the tract level, demographic MOE issues were widespread across the selected counties, indicating that uncertainty is concentrated in specific types of communities rather than being randomly distributed. As a result, communities most vulnerable to algorithmic bias are those with less reliable demographic and income estimates, especially smaller-population tracts and areas where minority populations are represented by relatively small counts. Because algorithmic decision-making systems often rely on these variables to allocate resources or classify need, high levels of uncertainty increase the risk of misclassification and inequitable outcomes. These data quality challenges are primarily driven by structural features of survey-based data collection, including limited sample sizes, population sparsity, and high variability within small geographic units. To mitigate these risks, departments should incorporate data quality metrics, such as margins of error, directly into analytic workflows rather than relying solely on point estimates, and apply caution thresholds when making decisions in high-uncertainty areas."
  },
  {
    "objectID": "labs/lab_1/lab1.html#specific-recommendations",
    "href": "labs/lab_1/lab1.html#specific-recommendations",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "6.3 Specific Recommendations",
    "text": "6.3 Specific Recommendations\nYour Task: Create a decision framework for algorithm implementation.\n\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\nalgorithm_recommendations &lt;- income_reliability %&gt;%\n  select(\n    county = NAME,\n    median_income = median_incomeE,\n    moe_percent = income_moe_pct,\n    reliability_category = income_reliability\n  ) %&gt;%\n  \n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\nmutate(\n    algorithm_recommendation = case_when(\n      reliability_category == \"High Confidence\" ~ \"Safe for algorithmic decisions\",\n      reliability_category == \"Moderate Confidence\" ~ \"Use with caution – monitor outcomes\",\n      reliability_category == \"Low Confidence\" ~ \"Requires manual review or additional data\"\n    ),\n    median_income = round(median_income, 0),\n    moe_percent = round(moe_percent, 2)\n  )\n\nalgorithm_recommendations %&gt;%\n  kable(\n    col.names = c(\n      \"County\",\n      \"Median Income\",\n      \"MOE (%)\",\n      \"Reliability Category\",\n      \"Algorithm Recommendation\"\n    ),\n    caption = \"Decision Framework for Algorithm Implementation Based on Data Reliability\"\n  )\n\n\nDecision Framework for Algorithm Implementation Based on Data Reliability\n\n\n\n\n\n\n\n\n\nCounty\nMedian Income\nMOE (%)\nReliability Category\nAlgorithm Recommendation\n\n\n\n\nAlameda\n122488\n1.00\nHigh Confidence\nSafe for algorithmic decisions\n\n\nAlpine\n101125\n17.25\nLow Confidence\nRequires manual review or additional data\n\n\nAmador\n74853\n8.08\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nButte\n66085\n3.42\nHigh Confidence\nSafe for algorithmic decisions\n\n\nCalaveras\n77526\n5.00\nHigh Confidence\nSafe for algorithmic decisions\n\n\nColusa\n69619\n8.25\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nContra Costa\n120020\n1.25\nHigh Confidence\nSafe for algorithmic decisions\n\n\nDel Norte\n61149\n7.16\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nEl Dorado\n99246\n3.36\nHigh Confidence\nSafe for algorithmic decisions\n\n\nFresno\n67756\n1.43\nHigh Confidence\nSafe for algorithmic decisions\n\n\nGlenn\n64033\n6.19\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nHumboldt\n57881\n3.68\nHigh Confidence\nSafe for algorithmic decisions\n\n\nImperial\n53847\n4.11\nHigh Confidence\nSafe for algorithmic decisions\n\n\nInyo\n63417\n8.60\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nKern\n63883\n2.07\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKings\n68540\n3.29\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLake\n56259\n4.34\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLassen\n59515\n5.97\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nLos Angeles\n83411\n0.53\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMadera\n73543\n3.87\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMarin\n142019\n2.89\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMariposa\n60021\n8.82\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nMendocino\n61335\n3.58\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMerced\n64772\n3.31\nHigh Confidence\nSafe for algorithmic decisions\n\n\nModoc\n54962\n9.80\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nMono\n82038\n18.76\nLow Confidence\nRequires manual review or additional data\n\n\nMonterey\n91043\n2.09\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNapa\n105809\n2.82\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNevada\n79395\n4.82\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOrange\n109361\n0.81\nHigh Confidence\nSafe for algorithmic decisions\n\n\nPlacer\n109375\n1.70\nHigh Confidence\nSafe for algorithmic decisions\n\n\nPlumas\n67885\n11.45\nLow Confidence\nRequires manual review or additional data\n\n\nRiverside\n84505\n1.26\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSacramento\n84010\n0.97\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Benito\n104451\n5.23\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nSan Bernardino\n77423\n1.04\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Diego\n96974\n1.02\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Francisco\n136689\n1.43\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Joaquin\n82837\n1.75\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Luis Obispo\n90158\n2.56\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Mateo\n149907\n1.75\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Barbara\n92332\n2.05\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Clara\n153792\n1.00\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Cruz\n104409\n3.04\nHigh Confidence\nSafe for algorithmic decisions\n\n\nShasta\n68347\n3.63\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSierra\n61108\n15.12\nLow Confidence\nRequires manual review or additional data\n\n\nSiskiyou\n53898\n4.90\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSolano\n97037\n1.78\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSonoma\n99266\n2.00\nHigh Confidence\nSafe for algorithmic decisions\n\n\nStanislaus\n74872\n1.83\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSutter\n72654\n4.71\nHigh Confidence\nSafe for algorithmic decisions\n\n\nTehama\n59029\n6.95\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nTrinity\n47317\n12.45\nLow Confidence\nRequires manual review or additional data\n\n\nTulare\n64474\n2.31\nHigh Confidence\nSafe for algorithmic decisions\n\n\nTuolumne\n70432\n6.66\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nVentura\n102141\n1.50\nHigh Confidence\nSafe for algorithmic decisions\n\n\nYolo\n85097\n2.74\nHigh Confidence\nSafe for algorithmic decisions\n\n\nYuba\n66693\n4.19\nHigh Confidence\nSafe for algorithmic decisions\n\n\n\n\n# Format as a professional table with kable()\n\nKey Recommendations:\nYour Task: Use your analysis results to provide specific guidance to the department.\n\nCounties suitable for immediate algorithmic implementation: Counties with high-confidence income estimates (MOE &lt; 5%) are appropriate for immediate algorithmic use because the underlying median income values are relatively stable and less likely to shift due to sampling noise. Based on the results, these counties include: Alameda, Butte, Calaveras, Contra Costa, El Dorado, Fresno, Humboldt, Imperial, Kern, Kings, Lake, Los Angeles, Madera, Marin, Mendocino, Merced, Monterey, Napa, Nevada, Orange, Placer, Riverside, Sacramento, San Bernardino, San Diego, San Francisco, San Joaquin, San Luis Obispo, San Mateo, Santa Barbara, Santa Clara, Santa Cruz, Shasta, Siskiyou, Solano, Sonoma, Stanislaus, Sutter, Tulare, Ventura, Yolo, and Yuba. In these places, automated prioritization or eligibility scoring based on income is less likely to systematically misclassify residents due to measurement error.\nCounties requiring additional oversight: Counties with moderate-confidence estimates (MOE 5–10%) can still use algorithmic tools, but only with monitoring because uncertainty is high enough that rankings and thresholds may be sensitive to small changes in the estimate. These counties include: Amador, Colusa, Del Norte, Glenn, Inyo, Lassen, Mariposa, Modoc, San Benito, Tehama, and Tuolumne. For these counties, the department should track outcomes for false positives or false negatives, and periodically re-run the analysis when updated ACS releases become available\nCounties needing alternative approaches: Counties with low-confidence estimates (MOE &gt; 10%) should not rely on automated income-based decisions without added safeguards, because the uncertainty is large enough to meaningfully distort classifications. These counties include Alpine, Mono, Plumas, Sierra, and Trinity. In these areas, the department should manual review for any high-stakes decisions or aggregating data to a larger geography to reduce uncertainty ## Questions for Further Investigation Does high MOE cluster spatially and does that pattern remain stable across different ACS years? Do certain demographic contexts consistently show higher uncertainty at the tract level? And how should algorithms adjust such thresholds?"
  },
  {
    "objectID": "labs/lab_1/lab1.html#submission-checklist",
    "href": "labs/lab_1/lab1.html#submission-checklist",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBefore submitting your portfolio link on Canvas:\n\nAll code chunks run without errors\nAll “[Fill this in]” prompts have been completed\nTables are properly formatted and readable\nExecutive summary addresses all four required components\nPortfolio navigation includes this assignment\nCensus API key is properly set\nDocument renders correctly to HTML\n\nRemember: Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at your-portfolio-url/labs/lab_1/your_file_name.html"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CPLN 5920 Portfolio",
    "section": "",
    "text": "This portfolio documents my learning journey in Public Policy Analytics (CPLN 5920).\n\n\nAdvanced spatial analysis and data science for urban planning and public policy.\n\n\n\n\nWeekly Notes: My learning reflections and key concepts\nLabs: Completed assignments and analyses\nFinal Project: Capstone modeling challenge\n\n\n\n\nMy name is Coco Zhou. I am currently a first-year MCP student concentrating in Smart Cities. I am taking this course because I am interested in learning more about how to analyze data through a public sector perspective.\n\n\n\n\nEmail: ziyanz27@upenn.edu\nGitHub: @cocoz1yn"
  },
  {
    "objectID": "index.html#about-this-course",
    "href": "index.html#about-this-course",
    "title": "CPLN 5920 Portfolio",
    "section": "",
    "text": "Advanced spatial analysis and data science for urban planning and public policy."
  },
  {
    "objectID": "index.html#portfolio-structure",
    "href": "index.html#portfolio-structure",
    "title": "CPLN 5920 Portfolio",
    "section": "",
    "text": "Weekly Notes: My learning reflections and key concepts\nLabs: Completed assignments and analyses\nFinal Project: Capstone modeling challenge"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "CPLN 5920 Portfolio",
    "section": "",
    "text": "My name is Coco Zhou. I am currently a first-year MCP student concentrating in Smart Cities. I am taking this course because I am interested in learning more about how to analyze data through a public sector perspective."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "CPLN 5920 Portfolio",
    "section": "",
    "text": "Email: ziyanz27@upenn.edu\nGitHub: @cocoz1yn"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html",
    "href": "labs/lab_0/lab0_template.html",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "",
    "text": "Welcome to your first lab! In this (not graded) assignment, you’ll practice the fundamental dplyr operations I overviewed in class using car sales data. This lab will help you get comfortable with:\n\nBasic data exploration\nColumn selection and manipulation\n\nCreating new variables\nFiltering data\nGrouping and summarizing\n\nInstructions: Copy this template into your portfolio repository under a lab_0/ folder, then complete each section with your code and answers. You will write the code under the comment section in each chunk. Be sure to also copy the data folder into your lab_0 folder."
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#data-structure-exploration",
    "href": "labs/lab_0/lab0_template.html#data-structure-exploration",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "1.1 Data Structure Exploration",
    "text": "1.1 Data Structure Exploration\nExplore the structure of your data and answer these questions:\n\n# Use glimpse() to see the data structure\n\nglimpse (car_data)\n\nRows: 50,000\nColumns: 7\n$ Manufacturer          &lt;chr&gt; \"Ford\", \"Porsche\", \"Ford\", \"Toyota\", \"VW\", \"Ford…\n$ Model                 &lt;chr&gt; \"Fiesta\", \"718 Cayman\", \"Mondeo\", \"RAV4\", \"Polo\"…\n$ `Engine size`         &lt;dbl&gt; 1.0, 4.0, 1.6, 1.8, 1.0, 1.4, 1.8, 1.4, 1.2, 2.0…\n$ `Fuel type`           &lt;chr&gt; \"Petrol\", \"Petrol\", \"Diesel\", \"Hybrid\", \"Petrol\"…\n$ `Year of manufacture` &lt;dbl&gt; 2002, 2016, 2014, 1988, 2006, 2018, 2010, 2015, …\n$ Mileage               &lt;dbl&gt; 127300, 57850, 39190, 210814, 127869, 33603, 866…\n$ Price                 &lt;dbl&gt; 3074, 49704, 24072, 1705, 4101, 29204, 14350, 30…\n\n# Check the column names\nnames(car_data)\n\n[1] \"Manufacturer\"        \"Model\"               \"Engine size\"        \n[4] \"Fuel type\"           \"Year of manufacture\" \"Mileage\"            \n[7] \"Price\"              \n\n# Look at the first few rows\nhead(car_data)\n\n# A tibble: 6 × 7\n  Manufacturer Model     `Engine size` `Fuel type` `Year of manufacture` Mileage\n  &lt;chr&gt;        &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;                       &lt;dbl&gt;   &lt;dbl&gt;\n1 Ford         Fiesta              1   Petrol                       2002  127300\n2 Porsche      718 Caym…           4   Petrol                       2016   57850\n3 Ford         Mondeo              1.6 Diesel                       2014   39190\n4 Toyota       RAV4                1.8 Hybrid                       1988  210814\n5 VW           Polo                1   Petrol                       2006  127869\n6 Ford         Focus               1.4 Petrol                       2018   33603\n# ℹ 1 more variable: Price &lt;dbl&gt;\n\n\nQuestions to answer: - How many rows and columns does the dataset have? - What types of variables do you see (numeric, character, etc.)? - Are there any column names that might cause problems? Why?\nYour answers: - Rows: 6 - Columns: 7\n- Variable types: categorical (nominal) variables - Problematic names: Engine size, Fuel type, Year of manufacture"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#tibble-vs-data-frame",
    "href": "labs/lab_0/lab0_template.html#tibble-vs-data-frame",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "1.2 Tibble vs Data Frame",
    "text": "1.2 Tibble vs Data Frame\nCompare how tibbles and data frames display:\n\n# Look at the tibble version (what we have)\nhead(car_data)\n\n# A tibble: 6 × 7\n  Manufacturer Model     `Engine size` `Fuel type` `Year of manufacture` Mileage\n  &lt;chr&gt;        &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;                       &lt;dbl&gt;   &lt;dbl&gt;\n1 Ford         Fiesta              1   Petrol                       2002  127300\n2 Porsche      718 Caym…           4   Petrol                       2016   57850\n3 Ford         Mondeo              1.6 Diesel                       2014   39190\n4 Toyota       RAV4                1.8 Hybrid                       1988  210814\n5 VW           Polo                1   Petrol                       2006  127869\n6 Ford         Focus               1.4 Petrol                       2018   33603\n# ℹ 1 more variable: Price &lt;dbl&gt;\n\n# Convert to regular data frame and display\ncar_df &lt;- as.data.frame(car_data)\nhead(car_df)\n\n  Manufacturer      Model Engine size Fuel type Year of manufacture Mileage\n1         Ford     Fiesta         1.0    Petrol                2002  127300\n2      Porsche 718 Cayman         4.0    Petrol                2016   57850\n3         Ford     Mondeo         1.6    Diesel                2014   39190\n4       Toyota       RAV4         1.8    Hybrid                1988  210814\n5           VW       Polo         1.0    Petrol                2006  127869\n6         Ford      Focus         1.4    Petrol                2018   33603\n  Price\n1  3074\n2 49704\n3 24072\n4  1705\n5  4101\n6 29204\n\n\nQuestion: What differences do you notice in how they print?\nYour answer: Tibbles print only the rows and columns that fit on the screen, display column types, and show the total number of rows and columns. In contrast, data frames print more rows by default and do not display column type information, making them less readable."
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#selecting-columns",
    "href": "labs/lab_0/lab0_template.html#selecting-columns",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "2.1 Selecting Columns",
    "text": "2.1 Selecting Columns\nPractice selecting different combinations of columns:\n\n# Select just Model and Mileage columns\nhead(select(car_df, Model, Mileage))\n\n       Model Mileage\n1     Fiesta  127300\n2 718 Cayman   57850\n3     Mondeo   39190\n4       RAV4  210814\n5       Polo  127869\n6      Focus   33603\n\n# Select Manufacturer, Price, and Fuel type\nhead(select(car_df, Manufacturer, Price, 'Fuel type'))\n\n  Manufacturer Price Fuel type\n1         Ford  3074    Petrol\n2      Porsche 49704    Petrol\n3         Ford 24072    Diesel\n4       Toyota  1705    Hybrid\n5           VW  4101    Petrol\n6         Ford 29204    Petrol\n\n# Challenge: Select all columns EXCEPT Engine Size\nhead(select(car_df, -'Engine size'))\n\n  Manufacturer      Model Fuel type Year of manufacture Mileage Price\n1         Ford     Fiesta    Petrol                2002  127300  3074\n2      Porsche 718 Cayman    Petrol                2016   57850 49704\n3         Ford     Mondeo    Diesel                2014   39190 24072\n4       Toyota       RAV4    Hybrid                1988  210814  1705\n5           VW       Polo    Petrol                2006  127869  4101\n6         Ford      Focus    Petrol                2018   33603 29204"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#renaming-columns",
    "href": "labs/lab_0/lab0_template.html#renaming-columns",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "2.2 Renaming Columns",
    "text": "2.2 Renaming Columns\nLet’s fix a problematic column name:\n\n# Rename 'Year of manufacture' to year\ncar_df &lt;- rename(car_df, year = `Year of manufacture`)\n\n# Check that it worked\nnames (car_df)\n\n[1] \"Manufacturer\" \"Model\"        \"Engine size\"  \"Fuel type\"    \"year\"        \n[6] \"Mileage\"      \"Price\"       \n\n\nQuestion: Why did we need backticks around Year of manufacture but not around year?\nYour answer: Backticks are required for Year of manufacture because it contains spaces and is not a valid R identifier. The column name year follows R’s naming rules and can be referenced directly without backticks."
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#calculate-car-age",
    "href": "labs/lab_0/lab0_template.html#calculate-car-age",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "3.1 Calculate Car Age",
    "text": "3.1 Calculate Car Age\n\n# Create an 'age' column (2025 minus year of manufacture)\ncar_df &lt;- mutate(\n  car_df,\n  age = 2025 - year,\n  mileage_per_year = Mileage / age\n)\n\n# Create a mileage_per_year column  \n\n\n# Look at your new columns\n#select(car_data, Model, year, age, Mileage, mileage_per_year)"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#categorize-cars",
    "href": "labs/lab_0/lab0_template.html#categorize-cars",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "3.2 Categorize Cars",
    "text": "3.2 Categorize Cars\n\n# Create a price_category column where if price is &lt; 15000, its is coded as budget, between 15000 and 30000 is midrange and greater than 30000 is mid-range (use case_when)\ncar_df &lt;- mutate(\n  car_df,\n  price_category = case_when(\n    Price &lt; 15000 ~ \"budget\",\n    Price &gt;= 15000 & Price &lt;= 30000 ~ \"midrange\",\n    Price &gt; 30000 ~ \"premium\"\n  )\n)\n\n# Check your categories select the new column and show it\nhead(select(car_df, Model, Price, price_category))\n\n       Model Price price_category\n1     Fiesta  3074         budget\n2 718 Cayman 49704        premium\n3     Mondeo 24072       midrange\n4       RAV4  1705         budget\n5       Polo  4101         budget\n6      Focus 29204       midrange"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#basic-filtering",
    "href": "labs/lab_0/lab0_template.html#basic-filtering",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "4.1 Basic Filtering",
    "text": "4.1 Basic Filtering\n\n# Find all Toyota cars\nhead(filter(car_df, Manufacturer == \"Toyota\"))\n\n  Manufacturer Model Engine size Fuel type year Mileage Price age\n1       Toyota  RAV4         1.8    Hybrid 1988  210814  1705  37\n2       Toyota Prius         1.4    Hybrid 2015   30663 30297  10\n3       Toyota  RAV4         2.2    Petrol 2007   79393 16026  18\n4       Toyota Yaris         1.4    Petrol 1998   97286  4046  27\n5       Toyota  RAV4         2.4    Hybrid 2003  117425 11667  22\n6       Toyota Yaris         1.2    Petrol 1992  245990   720  33\n  mileage_per_year price_category\n1         5697.676         budget\n2         3066.300        premium\n3         4410.722       midrange\n4         3603.185         budget\n5         5337.500         budget\n6         7454.242         budget\n\n# Find cars with mileage less than 30,000\nhead(filter(car_df, Mileage &lt; 30000))\n\n  Manufacturer      Model Engine size Fuel type year Mileage Price age\n1       Toyota       RAV4         2.0    Hybrid 2018   28381 52671   7\n2           VW       Golf         2.0    Petrol 2020   18985 36387   5\n3          BMW         M5         4.0    Petrol 2017   22759 97758   8\n4       Toyota       RAV4         2.4    Petrol 2018   24588 49125   7\n5           VW       Golf         2.0    Hybrid 2018   25017 36957   7\n6      Porsche 718 Cayman         2.4    Petrol 2021   14070 69526   4\n  mileage_per_year price_category\n1         4054.429        premium\n2         3797.000        premium\n3         2844.875        premium\n4         3512.571        premium\n5         3573.857        premium\n6         3517.500        premium\n\n# Find luxury cars (from price category) with low mileage\nhead(filter(car_df, price_category == \"premium\" & Mileage &lt; 30000))\n\n  Manufacturer      Model Engine size Fuel type year Mileage Price age\n1       Toyota       RAV4         2.0    Hybrid 2018   28381 52671   7\n2           VW       Golf         2.0    Petrol 2020   18985 36387   5\n3          BMW         M5         4.0    Petrol 2017   22759 97758   8\n4       Toyota       RAV4         2.4    Petrol 2018   24588 49125   7\n5           VW       Golf         2.0    Hybrid 2018   25017 36957   7\n6      Porsche 718 Cayman         2.4    Petrol 2021   14070 69526   4\n  mileage_per_year price_category\n1         4054.429        premium\n2         3797.000        premium\n3         2844.875        premium\n4         3512.571        premium\n5         3573.857        premium\n6         3517.500        premium"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#multiple-conditions",
    "href": "labs/lab_0/lab0_template.html#multiple-conditions",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "4.2 Multiple Conditions",
    "text": "4.2 Multiple Conditions\n\n# Find cars that are EITHER Honda OR Nissan\ncar_df %&gt;%\n  filter(Manufacturer == \"Honda\" | Manufacturer == \"Nissan\") %&gt;%\n  head()\n\n [1] Manufacturer     Model            Engine size      Fuel type       \n [5] year             Mileage          Price            age             \n [9] mileage_per_year price_category  \n&lt;0 rows&gt; (or 0-length row.names)\n\n# Find cars with price between $20,000 and $35,000\ncar_df %&gt;%\n  filter(Price &gt;= 20000 & Price &lt;= 35000) %&gt;%\n  head()\n\n  Manufacturer  Model Engine size Fuel type year Mileage Price age\n1         Ford Mondeo         1.6    Diesel 2014   39190 24072  11\n2         Ford  Focus         1.4    Petrol 2018   33603 29204   7\n3       Toyota  Prius         1.4    Hybrid 2015   30663 30297  10\n4       Toyota  Prius         1.4    Hybrid 2016   43893 29946   9\n5       Toyota  Prius         1.4    Hybrid 2016   43130 30085   9\n6           VW Passat         1.6    Petrol 2016   64344 23641   9\n  mileage_per_year price_category\n1         3562.727       midrange\n2         4800.429       midrange\n3         3066.300        premium\n4         4877.000       midrange\n5         4792.222        premium\n6         7149.333       midrange\n\n# Find diesel cars less than 10 years old\ndiesel_under_10 &lt;- car_df %&gt;%\n  filter(`Fuel type` == \"Diesel\", age &lt; 10)\n\nQuestion: How many diesel cars are less than 10 years old?\nYour answer: 2040"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#basic-summaries",
    "href": "labs/lab_0/lab0_template.html#basic-summaries",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "5.1 Basic Summaries",
    "text": "5.1 Basic Summaries\n\n# Calculate average price by manufacturer\navg_price_by_brand &lt;- car_data %&gt;%\n  group_by(Manufacturer) %&gt;%\n  summarize(avg_price = mean(Price, na.rm = TRUE))\n\navg_price_by_brand\n\n# A tibble: 5 × 2\n  Manufacturer avg_price\n  &lt;chr&gt;            &lt;dbl&gt;\n1 BMW             24429.\n2 Ford            10672.\n3 Porsche         29104.\n4 Toyota          14340.\n5 VW              10363.\n\n# Calculate average mileage by fuel type\navg_mileage_by_fuel &lt;- car_df %&gt;%\n  group_by(`Fuel type`) %&gt;%\n  summarize(avg_mileage = mean(Mileage, na.rm = TRUE))\n\navg_mileage_by_fuel\n\n# A tibble: 3 × 2\n  `Fuel type` avg_mileage\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Diesel          112667.\n2 Hybrid          111622.\n3 Petrol          112795.\n\n# Count cars by manufacturer\ncount_by_manufacturer &lt;- car_df %&gt;%\n  group_by(Manufacturer) %&gt;%\n  summarize(car_count = n())\n\ncount_by_manufacturer\n\n# A tibble: 5 × 2\n  Manufacturer car_count\n  &lt;chr&gt;            &lt;int&gt;\n1 BMW               4965\n2 Ford             14959\n3 Porsche           2609\n4 Toyota           12554\n5 VW               14913"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#categorical-summaries",
    "href": "labs/lab_0/lab0_template.html#categorical-summaries",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "5.2 Categorical Summaries",
    "text": "5.2 Categorical Summaries\n\n# Frequency table for price categories\ncar_df %&gt;%\n  count(price_category)\n\n  price_category     n\n1         budget 34040\n2       midrange  9782\n3        premium  6178"
  }
]