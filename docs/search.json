[
  {
    "objectID": "labs/lab_1/lab1.html",
    "href": "labs/lab_1/lab1.html",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the California Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n\n\n\nApply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders\n\n\n\n\nSubmit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/labs/lab_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Labs” menu."
  },
  {
    "objectID": "labs/lab_1/lab1.html#scenario",
    "href": "labs/lab_1/lab1.html#scenario",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the California Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues."
  },
  {
    "objectID": "labs/lab_1/lab1.html#learning-objectives",
    "href": "labs/lab_1/lab1.html#learning-objectives",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Apply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders"
  },
  {
    "objectID": "labs/lab_1/lab1.html#submission-instructions",
    "href": "labs/lab_1/lab1.html#submission-instructions",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Submit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/labs/lab_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Labs” menu."
  },
  {
    "objectID": "labs/lab_1/lab1.html#data-retrieval",
    "href": "labs/lab_1/lab1.html#data-retrieval",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.1 Data Retrieval",
    "text": "2.1 Data Retrieval\nYour Task: Use get_acs() to retrieve county-level data for your chosen state.\nRequirements: - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)\n- Year: 2022 - Survey: acs5 - Output format: wide\nHint: Remember to give your variables descriptive names using the variables = c(name = \"code\") syntax.\n\n# Write your get_acs() code here\ncounty_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    median_income = \"B19013_001\",\n    total_population = \"B01003_001\"\n  ),\n  state = my_state,\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n)\n\n# Clean the county names to remove state name and \"County\" \ncounty_data &lt;- county_data %&gt;%\n  mutate(\n    NAME = str_remove(NAME, \" County\"),\n    NAME = str_remove(NAME, \", California\")\n  )\n\n# Hint: use mutate() with str_remove()\n\n# Display the first few rows\nhead(county_data)\n\n# A tibble: 6 × 6\n  GEOID NAME   median_incomeE median_incomeM total_populationE total_populationM\n  &lt;chr&gt; &lt;chr&gt;           &lt;dbl&gt;          &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n1 06001 Alame…         122488           1231           1663823                NA\n2 06003 Alpine         101125          17442              1515               206\n3 06005 Amador          74853           6048             40577                NA\n4 06007 Butte           66085           2261            213605                NA\n5 06009 Calav…          77526           3875             45674                NA\n6 06011 Colusa          69619           5745             21811                NA"
  },
  {
    "objectID": "labs/lab_1/lab1.html#data-quality-assessment",
    "href": "labs/lab_1/lab1.html#data-quality-assessment",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.2 Data Quality Assessment",
    "text": "2.2 Data Quality Assessment\nYour Task: Calculate margin of error percentages and create reliability categories.\nRequirements: - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories: - High Confidence: MOE &lt; 5% - Moderate Confidence: MOE 5-10%\n- Low Confidence: MOE &gt; 10% - Create a flag for unreliable estimates (MOE &gt; 10%)\nHint: Use mutate() with case_when() for the categories.\n\n# Calculate MOE percentage and reliability categories using mutate()\nincome_reliability &lt;- county_data %&gt;%\n  mutate(\n    income_moe_pct = (median_incomeM / median_incomeE) * 100,\n\n    income_reliability = case_when(\n      income_moe_pct &lt; 5                     ~ \"High Confidence\",\n      income_moe_pct &gt;= 5 & income_moe_pct &lt;= 10 ~ \"Moderate Confidence\",\n      income_moe_pct &gt; 10                    ~ \"Low Confidence\"\n    ),\n\n    unreliable_income = income_moe_pct &gt; 10\n  )\n\n# Create a summary showing count of counties in each reliability category\nincome_reliability_summary &lt;- income_reliability %&gt;%\n  count(income_reliability) %&gt;%\n  mutate(\n    percent = (n / sum(n)) * 100\n  )\n\nincome_reliability_summary\n\n# A tibble: 3 × 3\n  income_reliability      n percent\n  &lt;chr&gt;               &lt;int&gt;   &lt;dbl&gt;\n1 High Confidence        42   72.4 \n2 Low Confidence          5    8.62\n3 Moderate Confidence    11   19.0 \n\n# Hint: use count() and mutate() to add percentages"
  },
  {
    "objectID": "labs/lab_1/lab1.html#high-uncertainty-counties",
    "href": "labs/lab_1/lab1.html#high-uncertainty-counties",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "2.3 High Uncertainty Counties",
    "text": "2.3 High Uncertainty Counties\nYour Task: Identify the 5 counties with the highest MOE percentages.\nRequirements: - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using kable()\nHint: Use arrange(), slice(), and select() functions.\n\n# Create table of top 5 counties by MOE percentage\ntop5_high_uncertainty &lt;- income_reliability %&gt;%\n  arrange(desc(income_moe_pct)) %&gt;%\n  slice(1:5) %&gt;%\n  select(\n    county = NAME,\n    median_income = median_incomeE,\n    margin_of_error = median_incomeM,\n    moe_percent = income_moe_pct,\n    reliability = income_reliability\n  ) %&gt;%\n  mutate(\n    median_income = scales::dollar(median_income, accuracy = 1),\n    margin_of_error = scales::dollar(margin_of_error, accuracy = 1),\n    moe_percent = round(moe_percent, 2)\n  )\n\n# Format as table with kable() - include appropriate column names and caption\ntop5_high_uncertainty %&gt;%\n  kable(\n    col.names = c(\"County\", \"Median Household Income\", \"Margin of Error\", \"MOE (%)\", \"Reliability Category\"),\n    caption = \"Top 5 California Counties with the Highest Median Income MOE Percentages (ACS 2022 5-year)\"\n  )\n\n\nTop 5 California Counties with the Highest Median Income MOE Percentages (ACS 2022 5-year)\n\n\n\n\n\n\n\n\n\nCounty\nMedian Household Income\nMargin of Error\nMOE (%)\nReliability Category\n\n\n\n\nMono\n$82,038\n$15,388\n18.76\nLow Confidence\n\n\nAlpine\n$101,125\n$17,442\n17.25\nLow Confidence\n\n\nSierra\n$61,108\n$9,237\n15.12\nLow Confidence\n\n\nTrinity\n$47,317\n$5,890\n12.45\nLow Confidence\n\n\nPlumas\n$67,885\n$7,772\n11.45\nLow Confidence\n\n\n\n\n\nData Quality Commentary:\nCounties with high income margin of error percentages are more likely to be poorly represented because the underlying estimates are more uncertain. These counties are often rural or have highly variable income distributions, which can reduce survey sample sizes and increase estimation error. As a result, algorithms using this data may misclassify economic conditions."
  },
  {
    "objectID": "labs/lab_1/lab1.html#focus-area-selection",
    "href": "labs/lab_1/lab1.html#focus-area-selection",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.1 Focus Area Selection",
    "text": "3.1 Focus Area Selection\nYour Task: Select 2-3 counties from your reliability analysis for detailed tract-level study.\nStrategy: Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n# Use filter() to select 2-3 counties from your county_reliability data\nselected_counties &lt;- income_reliability %&gt;%\n  filter(income_reliability %in% c(\"High Confidence\", \"Moderate Confidence\", \"Low Confidence\")) %&gt;%\n  group_by(income_reliability) %&gt;%\n  slice_max(income_moe_pct, n = 1) %&gt;%\n  ungroup() %&gt;%\n\n# Store the selected counties in a variable called selected_counties\nselect(\n    county = NAME,\n    median_income = median_incomeE,\n    moe_percent = income_moe_pct,\n    reliability_category = income_reliability\n  )\n\n# Display the selected counties with their key characteristics\nselected_counties\n\n# A tibble: 3 × 4\n  county    median_income moe_percent reliability_category\n  &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;               \n1 Calaveras         77526        5.00 High Confidence     \n2 Mono              82038       18.8  Low Confidence      \n3 Modoc             54962        9.80 Moderate Confidence \n\n# Show: county name, median income, MOE percentage, reliability category\n\nComment on the output: The selected counties are different in data reliability. High-confidence counties show relatively low income uncertainty and low-confidence counties have higher MOE percentages. This contrast shows how data quality can vary significantly across regions when applying income based algorithms uniformly across all counties."
  },
  {
    "objectID": "labs/lab_1/lab1.html#tract-level-demographics",
    "href": "labs/lab_1/lab1.html#tract-level-demographics",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.2 Tract-Level Demographics",
    "text": "3.2 Tract-Level Demographics\nYour Task: Get demographic data for census tracts in your selected counties.\nRequirements: - Geography: tract level - Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001) - Use the same state and year as before - Output format: wide - Challenge: You’ll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n# Define your race/ethnicity variables with descriptive names\nrace_vars &lt;- c(\n  total_pop = \"B03002_001\",\n  white_alone = \"B03002_003\",\n  black_alone = \"B03002_004\",\n  hispanic_latino = \"B03002_012\"\n)\n# Use get_acs() to retrieve tract-level data\n# Hint: You may need to specify county codes in the county parameter\ntract_data &lt;- get_acs(\n  geography = \"tract\",\n  variables = c(\n    total_population = \"B03002_001\",\n    white_alone = \"B03002_003\",\n    black_alone = \"B03002_004\",\n    hispanic_latino = \"B03002_012\"\n  ),\n  state = my_state,\n  county = c(\"009\", \"051\", \"049\"),    #County codes from previous table\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n)\n\n# Calculate percentage of each group using mutate()\ntract_data &lt;- tract_data %&gt;%\n  mutate(\n    pct_white = (white_aloneE / total_populationE) * 100,\n    pct_black = (black_aloneE / total_populationE) * 100,\n    pct_hispanic = (hispanic_latinoE / total_populationE) * 100\n  )\n\n# Create percentages for white, Black, and Hispanic populations\ntract_data &lt;- tract_data %&gt;%\n  mutate(\n    county_fips = str_sub(GEOID, 3, 5),\n    tract_code = str_sub(GEOID, 6, 11),\n    county_name = str_extract(NAME, \"(?&lt;=; )[^;]+(?=County)\")  \n  )\n\n# Add readable tract and county name columns using str_extract() or similar\ntract_data %&gt;%\n  select(county_name, tract_code, total_populationE, pct_white, pct_black, pct_hispanic) %&gt;%\n  head()\n\n# A tibble: 6 × 6\n  county_name  tract_code total_populationE pct_white pct_black pct_hispanic\n  &lt;chr&gt;        &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 \"Calaveras \" 000121                  4326      83.1    0              8.30\n2 \"Calaveras \" 000122                  3297      86.7    1.15           6.28\n3 \"Calaveras \" 000123                  2940      67.9    4.05          23.8 \n4 \"Calaveras \" 000124                  2152      77.5    0             19.3 \n5 \"Calaveras \" 000220                  6271      67.2    0.0159        21.4 \n6 \"Calaveras \" 000221                  6691      82.5    0             12.9"
  },
  {
    "objectID": "labs/lab_1/lab1.html#demographic-analysis",
    "href": "labs/lab_1/lab1.html#demographic-analysis",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "3.3 Demographic Analysis",
    "text": "3.3 Demographic Analysis\nYour Task: Analyze the demographic patterns in your selected areas.\n\n# Find the tract with the highest percentage of Hispanic/Latino residents\ntop_hispanic_tract &lt;- tract_data %&gt;%\n  arrange(desc(pct_hispanic)) %&gt;%\n  slice(1) %&gt;%\n  select(NAME, GEOID, county_fips, tract_code, total_populationE, pct_white, pct_black, pct_hispanic)\n\n# Hint: use arrange() and slice() to get the top tract\ntop_hispanic_tract %&gt;%\n  kable(\n    col.names = c(\"Tract Name\", \"GEOID\", \"County FIPS\", \"Tract Code\", \"Total Pop\", \"% White\", \"% Black\", \"% Hispanic/Latino\"),\n    caption = \"Tract with the Highest Percentage of Hispanic/Latino Residents (Selected Counties)\"\n  )\n\n\nTract with the Highest Percentage of Hispanic/Latino Residents (Selected Counties)\n\n\n\n\n\n\n\n\n\n\n\n\nTract Name\nGEOID\nCounty FIPS\nTract Code\nTotal Pop\n% White\n% Black\n% Hispanic/Latino\n\n\n\n\nCensus Tract 2.01; Mono County; California\n06051000201\n051\n000201\n3213\n63.99004\n0\n33.70682\n\n\n\n\n# Calculate average demographics by county using group_by() and summarize()\ncounty_demographics_summary &lt;- tract_data %&gt;%\n  group_by(county_fips) %&gt;%\n  summarize(\n    n_tracts = n(),\n    avg_pct_white = mean(pct_white, na.rm = TRUE),\n    avg_pct_black = mean(pct_black, na.rm = TRUE),\n    avg_pct_hispanic = mean(pct_hispanic, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(avg_pct_hispanic)) %&gt;%\n  mutate(\n    avg_pct_white = round(avg_pct_white, 2),\n    avg_pct_black = round(avg_pct_black, 2),\n    avg_pct_hispanic = round(avg_pct_hispanic, 2)\n  )\n\n# Show: number of tracts, average percentage for each racial/ethnic group\ncounty_demographics_summary %&gt;%\n  kable(\n    col.names = c(\n      \"County FIPS\",\n      \"Number of Tracts\",\n      \"Avg % White\",\n      \"Avg % Black\",\n      \"Avg % Hispanic/Latino\"\n    ),\n    caption = \"Average Tract Demographics by County (Selected Counties)\"\n  )\n\n\nAverage Tract Demographics by County (Selected Counties)\n\n\n\n\n\n\n\n\n\nCounty FIPS\nNumber of Tracts\nAvg % White\nAvg % Black\nAvg % Hispanic/Latino\n\n\n\n\n051\n4\n64.14\n0.23\n27.82\n\n\n049\n4\n76.57\n1.43\n15.06\n\n\n009\n14\n80.98\n0.93\n11.60\n\n\n\n\n# Create a nicely formatted table of your results using kable()"
  },
  {
    "objectID": "labs/lab_1/lab1.html#moe-analysis-for-demographic-variables",
    "href": "labs/lab_1/lab1.html#moe-analysis-for-demographic-variables",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "4.1 MOE Analysis for Demographic Variables",
    "text": "4.1 MOE Analysis for Demographic Variables\nYour Task: Examine margins of error for demographic variables to see if some communities have less reliable data.\nRequirements: - Calculate MOE percentages for each demographic variable - Flag tracts where any demographic variable has MOE &gt; 15% - Create summary statistics\n\n# Calculate MOE percentages for white, Black, and Hispanic variables\ntract_data &lt;- tract_data %&gt;%\n  mutate(\n    white_moe_pct = (white_aloneM / white_aloneE) * 100,\n    black_moe_pct = (black_aloneM / black_aloneE) * 100,\n    hispanic_moe_pct = (hispanic_latinoM / hispanic_latinoE) * 100\n  )\n# Hint: use the same formula as before (margin/estimate * 100)\n\n# Create a flag for tracts with high MOE on any demographic variable\ntract_data &lt;- tract_data %&gt;%\n  mutate(\n    high_demo_moe = ifelse(\n      white_moe_pct &gt; 15 | black_moe_pct &gt; 15 | hispanic_moe_pct &gt; 15,\n      TRUE,\n      FALSE\n    )\n  )\n\n# Use logical operators (| for OR) in an ifelse() statement\n\n# Create summary statistics showing how many tracts have data quality issues\ndemo_moe_summary &lt;- tract_data %&gt;%\n  group_by(county_name) %&gt;%\n  summarize(\n    total_tracts = n(),\n    tracts_high_moe = sum(high_demo_moe, na.rm = TRUE),\n    percent_high_moe = (tracts_high_moe / total_tracts) * 100\n  )\n\ndemo_moe_summary\n\n# A tibble: 3 × 4\n  county_name  total_tracts tracts_high_moe percent_high_moe\n  &lt;chr&gt;               &lt;int&gt;           &lt;int&gt;            &lt;dbl&gt;\n1 \"Calaveras \"           14              14              100\n2 \"Modoc \"                4               4              100\n3 \"Mono \"                 4               4              100"
  },
  {
    "objectID": "labs/lab_1/lab1.html#pattern-analysis",
    "href": "labs/lab_1/lab1.html#pattern-analysis",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "4.2 Pattern Analysis",
    "text": "4.2 Pattern Analysis\nYour Task: Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n# Group tracts by whether they have high MOE issues\n\n# Due to previous results which reflects all high percentages in MOE, the data is now classified as any demographic that has MOE &gt; 15% but individually selected\ntract_data1 &lt;- tract_data %&gt;%\n  mutate(\n    high_white = white_moe_pct &gt;15,\n    high_black = black_moe_pct &gt;15,\n    high_hispanic = hispanic_moe_pct &gt;15,\n    high_count = high_white + high_black + high_hispanic,\n    severity = case_when(\n      high_count == 3 ~ \"High\",\n      high_count == 2 ~ \"Moderate\",\n      TRUE ~ \"Low\"\n    )\n  )\n \n# Calculate average characteristics for each group:\npattern_tbl &lt;- tract_data1 %&gt;%\n  group_by(severity) %&gt;%\n  summarise(\n    n_tract = n(),\n    pop = mean(total_populationE, na.rm = TRUE),\n    avg_white = weighted.mean(pct_white, total_populationE, na.rm = TRUE),\n    avg_black = weighted.mean(pct_black, total_populationE, na.rm = TRUE),\n    avg_hispanic = weighted.mean(pct_hispanic, total_populationE, na.rm = TRUE),\n  )\n\n# - population size, demographic percentages\n\n\n# Use group_by() and summarize() to create this comparison\n# Create a professional table showing the patterns\nkable(pattern_tbl, \n      align = c(\"l\",\"l\",\"l\",\"l\",\"l\"), \n      col.names = c(\"Severity\", \"Tracts Number\", \"Average Population\", \"Average White Proportion\", \"Average Black Proportion\", \"Average Hispanic Proportion\"),\n      caption = \"Pattern of tarcts with different severity of MOE issues\")\n\n\nPattern of tarcts with different severity of MOE issues\n\n\n\n\n\n\n\n\n\n\nSeverity\nTracts Number\nAverage Population\nAverage White Proportion\nAverage Black Proportion\nAverage Hispanic Proportion\n\n\n\n\nHigh\n19\n2989.684\n74.18844\n0.813323\n17.55158\n\n\nModerate\n3\n3580.000\n80.63315\n1.648045\n10.55866\n\n\n\n\n\nPattern Analysis: The results suggest that demographic data quality issues are not randomly distributed across tracts. Tracts with high demographic MOE tend to have smaller average populations and differ in racial and ethnic composition compared to tracts with more reliable data. These patterns likely reflect lower survey sample sizes and higher population variability in certain communities, which increases uncertainty in ACS estimates."
  },
  {
    "objectID": "labs/lab_1/lab1.html#analysis-integration-and-professional-summary",
    "href": "labs/lab_1/lab1.html#analysis-integration-and-professional-summary",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "5.1 Analysis Integration and Professional Summary",
    "text": "5.1 Analysis Integration and Professional Summary\nYour Task: Write an executive summary that integrates findings from all four analyses.\nExecutive Summary Requirements: 1. Overall Pattern Identification: Counties and census tracts with smaller populations and uneven demographic distributions tend to exhibit higher margins of error, particularly for income and race/ethnicity variables. At the tract level, demographic MOE issues were widespread across the selected counties, showing that uncertainty is concentrated in specific types of communities. 2. Equity Assessment: Communities most vulnerable to algorithmic bias are those with less reliable demographic and income estimates, especially smaller-population tracts and areas with minority populations represented by relatively small counts. Because algorithmic decision-making systems often rely on these variables to allocate resources, it increases the risk of misclassification. 3. Root Cause Analysis: The primary drivers of data quality issues are structural features of survey-based data collection, including limited sample sizes, population sparsity, and high variability within small geographic units. 4. Strategic Recommendations: To mitigate these risks, departments should incorporate data quality metrics, such as margins of error, directly into analytic rather than relying solely on point estimates.Also, decision making systems should apply caution thresholds in high-uncertainty areas\nExecutive Summary:\nCounties and census tracts with smaller populations and uneven/ more POC demographic distributions tend to exhibit higher margins of error, particularly for income and race and ethnicity variables. At the tract level, demographic MOE issues were widespread across the selected counties, indicating that uncertainty is concentrated in specific types of communities rather than being randomly distributed. As a result, communities most vulnerable to algorithmic bias are those with less reliable demographic and income estimates, especially smaller-population tracts and areas where minority populations are represented by relatively small counts. Because algorithmic decision-making systems often rely on these variables to allocate resources or classify need, high levels of uncertainty increase the risk of misclassification and inequitable outcomes. These data quality challenges are primarily driven by structural features of survey-based data collection, including limited sample sizes, population sparsity, and high variability within small geographic units. To mitigate these risks, departments should incorporate data quality metrics, such as margins of error, directly into analytic workflows rather than relying solely on point estimates, and apply caution thresholds when making decisions in high-uncertainty areas."
  },
  {
    "objectID": "labs/lab_1/lab1.html#specific-recommendations",
    "href": "labs/lab_1/lab1.html#specific-recommendations",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "6.3 Specific Recommendations",
    "text": "6.3 Specific Recommendations\nYour Task: Create a decision framework for algorithm implementation.\n\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\nalgorithm_recommendations &lt;- income_reliability %&gt;%\n  select(\n    county = NAME,\n    median_income = median_incomeE,\n    moe_percent = income_moe_pct,\n    reliability_category = income_reliability\n  ) %&gt;%\n  \n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\nmutate(\n    algorithm_recommendation = case_when(\n      reliability_category == \"High Confidence\" ~ \"Safe for algorithmic decisions\",\n      reliability_category == \"Moderate Confidence\" ~ \"Use with caution – monitor outcomes\",\n      reliability_category == \"Low Confidence\" ~ \"Requires manual review or additional data\"\n    ),\n    median_income = round(median_income, 0),\n    moe_percent = round(moe_percent, 2)\n  )\n\nalgorithm_recommendations %&gt;%\n  kable(\n    col.names = c(\n      \"County\",\n      \"Median Income\",\n      \"MOE (%)\",\n      \"Reliability Category\",\n      \"Algorithm Recommendation\"\n    ),\n    caption = \"Decision Framework for Algorithm Implementation Based on Data Reliability\"\n  )\n\n\nDecision Framework for Algorithm Implementation Based on Data Reliability\n\n\n\n\n\n\n\n\n\nCounty\nMedian Income\nMOE (%)\nReliability Category\nAlgorithm Recommendation\n\n\n\n\nAlameda\n122488\n1.00\nHigh Confidence\nSafe for algorithmic decisions\n\n\nAlpine\n101125\n17.25\nLow Confidence\nRequires manual review or additional data\n\n\nAmador\n74853\n8.08\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nButte\n66085\n3.42\nHigh Confidence\nSafe for algorithmic decisions\n\n\nCalaveras\n77526\n5.00\nHigh Confidence\nSafe for algorithmic decisions\n\n\nColusa\n69619\n8.25\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nContra Costa\n120020\n1.25\nHigh Confidence\nSafe for algorithmic decisions\n\n\nDel Norte\n61149\n7.16\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nEl Dorado\n99246\n3.36\nHigh Confidence\nSafe for algorithmic decisions\n\n\nFresno\n67756\n1.43\nHigh Confidence\nSafe for algorithmic decisions\n\n\nGlenn\n64033\n6.19\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nHumboldt\n57881\n3.68\nHigh Confidence\nSafe for algorithmic decisions\n\n\nImperial\n53847\n4.11\nHigh Confidence\nSafe for algorithmic decisions\n\n\nInyo\n63417\n8.60\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nKern\n63883\n2.07\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKings\n68540\n3.29\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLake\n56259\n4.34\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLassen\n59515\n5.97\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nLos Angeles\n83411\n0.53\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMadera\n73543\n3.87\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMarin\n142019\n2.89\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMariposa\n60021\n8.82\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nMendocino\n61335\n3.58\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMerced\n64772\n3.31\nHigh Confidence\nSafe for algorithmic decisions\n\n\nModoc\n54962\n9.80\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nMono\n82038\n18.76\nLow Confidence\nRequires manual review or additional data\n\n\nMonterey\n91043\n2.09\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNapa\n105809\n2.82\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNevada\n79395\n4.82\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOrange\n109361\n0.81\nHigh Confidence\nSafe for algorithmic decisions\n\n\nPlacer\n109375\n1.70\nHigh Confidence\nSafe for algorithmic decisions\n\n\nPlumas\n67885\n11.45\nLow Confidence\nRequires manual review or additional data\n\n\nRiverside\n84505\n1.26\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSacramento\n84010\n0.97\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Benito\n104451\n5.23\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nSan Bernardino\n77423\n1.04\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Diego\n96974\n1.02\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Francisco\n136689\n1.43\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Joaquin\n82837\n1.75\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Luis Obispo\n90158\n2.56\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Mateo\n149907\n1.75\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Barbara\n92332\n2.05\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Clara\n153792\n1.00\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Cruz\n104409\n3.04\nHigh Confidence\nSafe for algorithmic decisions\n\n\nShasta\n68347\n3.63\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSierra\n61108\n15.12\nLow Confidence\nRequires manual review or additional data\n\n\nSiskiyou\n53898\n4.90\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSolano\n97037\n1.78\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSonoma\n99266\n2.00\nHigh Confidence\nSafe for algorithmic decisions\n\n\nStanislaus\n74872\n1.83\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSutter\n72654\n4.71\nHigh Confidence\nSafe for algorithmic decisions\n\n\nTehama\n59029\n6.95\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nTrinity\n47317\n12.45\nLow Confidence\nRequires manual review or additional data\n\n\nTulare\n64474\n2.31\nHigh Confidence\nSafe for algorithmic decisions\n\n\nTuolumne\n70432\n6.66\nModerate Confidence\nUse with caution – monitor outcomes\n\n\nVentura\n102141\n1.50\nHigh Confidence\nSafe for algorithmic decisions\n\n\nYolo\n85097\n2.74\nHigh Confidence\nSafe for algorithmic decisions\n\n\nYuba\n66693\n4.19\nHigh Confidence\nSafe for algorithmic decisions\n\n\n\n\n# Format as a professional table with kable()\n\nKey Recommendations:\nYour Task: Use your analysis results to provide specific guidance to the department.\n\nCounties suitable for immediate algorithmic implementation: Counties with high-confidence income estimates (MOE &lt; 5%) are appropriate for immediate algorithmic use because the underlying median income values are relatively stable and less likely to shift due to sampling noise. Based on the results, these counties include: Alameda, Butte, Calaveras, Contra Costa, El Dorado, Fresno, Humboldt, Imperial, Kern, Kings, Lake, Los Angeles, Madera, Marin, Mendocino, Merced, Monterey, Napa, Nevada, Orange, Placer, Riverside, Sacramento, San Bernardino, San Diego, San Francisco, San Joaquin, San Luis Obispo, San Mateo, Santa Barbara, Santa Clara, Santa Cruz, Shasta, Siskiyou, Solano, Sonoma, Stanislaus, Sutter, Tulare, Ventura, Yolo, and Yuba. In these places, automated prioritization or eligibility scoring based on income is less likely to systematically misclassify residents due to measurement error.\nCounties requiring additional oversight: Counties with moderate-confidence estimates (MOE 5–10%) can still use algorithmic tools, but only with monitoring because uncertainty is high enough that rankings and thresholds may be sensitive to small changes in the estimate. These counties include: Amador, Colusa, Del Norte, Glenn, Inyo, Lassen, Mariposa, Modoc, San Benito, Tehama, and Tuolumne. For these counties, the department should track outcomes for false positives or false negatives, and periodically re-run the analysis when updated ACS releases become available\nCounties needing alternative approaches: Counties with low-confidence estimates (MOE &gt; 10%) should not rely on automated income-based decisions without added safeguards, because the uncertainty is large enough to meaningfully distort classifications. These counties include Alpine, Mono, Plumas, Sierra, and Trinity. In these areas, the department should manual review for any high-stakes decisions or aggregating data to a larger geography to reduce uncertainty ## Questions for Further Investigation Does high MOE cluster spatially and does that pattern remain stable across different ACS years? Do certain demographic contexts consistently show higher uncertainty at the tract level? And how should algorithms adjust such thresholds?"
  },
  {
    "objectID": "labs/lab_1/lab1.html#submission-checklist",
    "href": "labs/lab_1/lab1.html#submission-checklist",
    "title": "Lab 1: Census Data Quality for Policy Decisions",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBefore submitting your portfolio link on Canvas:\n\nAll code chunks run without errors\nAll “[Fill this in]” prompts have been completed\nTables are properly formatted and readable\nExecutive summary addresses all four required components\nPortfolio navigation includes this assignment\nCensus API key is properly set\nDocument renders correctly to HTML\n\nRemember: Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at your-portfolio-url/labs/lab_1/your_file_name.html"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CPLN 5920 Portfolio",
    "section": "",
    "text": "This portfolio documents my learning journey in Public Policy Analytics (CPLN 5920).\n\n\nAdvanced spatial analysis and data science for urban planning and public policy.\n\n\n\n\nWeekly Notes: My learning reflections and key concepts\nLabs: Completed assignments and analyses\nFinal Project: Capstone modeling challenge\n\n\n\n\nMy name is Coco Zhou. I am currently a first-year MCP student concentrating in Smart Cities. I am taking this course because I am interested in learning more about how to analyze data through a public sector perspective.\n\n\n\n\nEmail: ziyanz27@upenn.edu\nGitHub: @cocoz1yn"
  },
  {
    "objectID": "index.html#about-this-course",
    "href": "index.html#about-this-course",
    "title": "CPLN 5920 Portfolio",
    "section": "",
    "text": "Advanced spatial analysis and data science for urban planning and public policy."
  },
  {
    "objectID": "index.html#portfolio-structure",
    "href": "index.html#portfolio-structure",
    "title": "CPLN 5920 Portfolio",
    "section": "",
    "text": "Weekly Notes: My learning reflections and key concepts\nLabs: Completed assignments and analyses\nFinal Project: Capstone modeling challenge"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "CPLN 5920 Portfolio",
    "section": "",
    "text": "My name is Coco Zhou. I am currently a first-year MCP student concentrating in Smart Cities. I am taking this course because I am interested in learning more about how to analyze data through a public sector perspective."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "CPLN 5920 Portfolio",
    "section": "",
    "text": "Email: ziyanz27@upenn.edu\nGitHub: @cocoz1yn"
  },
  {
    "objectID": "exercise/week3_lab_exercise.html",
    "href": "exercise/week3_lab_exercise.html",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "",
    "text": "# Load required packages\nlibrary(tidyverse)\nlibrary(tidycensus)\nlibrary(scales)\nlibrary(RColorBrewer)\n# Set your Census API key if you haven't already\ncensus_api_key(Sys.getenv(\"CENSUS_API_KEY\"))\n\n# We'll use Pennsylvania data for consistency with previous weeks\nstate_choice &lt;- \"PA\""
  },
  {
    "objectID": "exercise/week3_lab_exercise.html#setup-and-data-loading",
    "href": "exercise/week3_lab_exercise.html#setup-and-data-loading",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "",
    "text": "# Load required packages\nlibrary(tidyverse)\nlibrary(tidycensus)\nlibrary(scales)\nlibrary(RColorBrewer)\n# Set your Census API key if you haven't already\ncensus_api_key(Sys.getenv(\"CENSUS_API_KEY\"))\n\n# We'll use Pennsylvania data for consistency with previous weeks\nstate_choice &lt;- \"PA\""
  },
  {
    "objectID": "exercise/week3_lab_exercise.html#exercise-0-finding-census-variable-codes",
    "href": "exercise/week3_lab_exercise.html#exercise-0-finding-census-variable-codes",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 0: Finding Census Variable Codes",
    "text": "Exercise 0: Finding Census Variable Codes\nThe Challenge: You know you want data on total population, median income, and median age, but you don’t know the specific Census variable codes. How do you find them?\n\n0.1 Load the Variable Dictionary\n\n# Load all available variables for ACS 5-year 2022\nacs_vars_2022 &lt;- load_variables(2022, \"acs5\", cache = TRUE)\n\n# Look at the structure\nglimpse(acs_vars_2022)\n\nRows: 28,152\nColumns: 4\n$ name      &lt;chr&gt; \"B01001A_001\", \"B01001A_002\", \"B01001A_003\", \"B01001A_004\", …\n$ label     &lt;chr&gt; \"Estimate!!Total:\", \"Estimate!!Total:!!Male:\", \"Estimate!!To…\n$ concept   &lt;chr&gt; \"Sex by Age (White Alone)\", \"Sex by Age (White Alone)\", \"Sex…\n$ geography &lt;chr&gt; \"tract\", \"tract\", \"tract\", \"tract\", \"tract\", \"tract\", \"tract…\n\nhead(acs_vars_2022)\n\n# A tibble: 6 × 4\n  name        label                                   concept          geography\n  &lt;chr&gt;       &lt;chr&gt;                                   &lt;chr&gt;            &lt;chr&gt;    \n1 B01001A_001 Estimate!!Total:                        Sex by Age (Whi… tract    \n2 B01001A_002 Estimate!!Total:!!Male:                 Sex by Age (Whi… tract    \n3 B01001A_003 Estimate!!Total:!!Male:!!Under 5 years  Sex by Age (Whi… tract    \n4 B01001A_004 Estimate!!Total:!!Male:!!5 to 9 years   Sex by Age (Whi… tract    \n5 B01001A_005 Estimate!!Total:!!Male:!!10 to 14 years Sex by Age (Whi… tract    \n6 B01001A_006 Estimate!!Total:!!Male:!!15 to 17 years Sex by Age (Whi… tract    \n\n\nWhat you see:\n\nname: The variable code (e.g., “B01003_001”)\nlabel: Human-readable description\nconcept: The broader table this variable belongs to\n\n\n\n0.2 Search for Population Variables\nYour Task: Find the variable code for total population.\n\n# Search for population-related variables\npopulation_vars &lt;- acs_vars_2022 %&gt;%\n  filter(str_detect(label, \"Total.*population\"))\n\n# Look at the results\nhead(population_vars, 10)\n\n# A tibble: 10 × 4\n   name       label                                            concept geography\n   &lt;chr&gt;      &lt;chr&gt;                                            &lt;chr&gt;   &lt;chr&gt;    \n 1 B16008_002 \"Estimate!!Total:!!Native population:\"           Citize… tract    \n 2 B16008_003 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 3 B16008_004 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 4 B16008_005 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 5 B16008_006 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 6 B16008_007 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 7 B16008_008 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 8 B16008_009 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n 9 B16008_010 \"Estimate!!Total:!!Native population:!!5 to 17 … Citize… tract    \n10 B16008_011 \"Estimate!!Total:!!Native population:!!18 years… Citize… tract    \n\n# Or search in the concept field\npop_concept &lt;- acs_vars_2022 %&gt;%\n  filter(str_detect(concept, \"Total Population\"))\n\nhead(pop_concept)\n\n# A tibble: 6 × 4\n  name        label                             concept                geography\n  &lt;chr&gt;       &lt;chr&gt;                             &lt;chr&gt;                  &lt;chr&gt;    \n1 B01003_001  Estimate!!Total                   Total Population       block gr…\n2 B25008A_001 Estimate!!Total:                  Total Population in O… block gr…\n3 B25008A_002 Estimate!!Total:!!Owner occupied  Total Population in O… block gr…\n4 B25008A_003 Estimate!!Total:!!Renter occupied Total Population in O… block gr…\n5 B25008B_001 Estimate!!Total:                  Total Population in O… block gr…\n6 B25008B_002 Estimate!!Total:!!Owner occupied  Total Population in O… block gr…\n\n\nTip: Look for “Total” followed by “population” - usually B01003_001\n\n\n0.3 Search for Income Variables\nYour Task: Find median household income variables.\n\n# Search for median income\nincome_vars &lt;- acs_vars_2022 %&gt;%\n  filter(str_detect(label, \"[Mm]edian.*income\"))\n\n# Look specifically for household income\nhousehold_income &lt;- income_vars %&gt;%\n  filter(str_detect(label, \"household\"))\n\nprint(\"Household income variables:\")\n\n[1] \"Household income variables:\"\n\nhead(household_income)\n\n# A tibble: 6 × 4\n  name        label                                            concept geography\n  &lt;chr&gt;       &lt;chr&gt;                                            &lt;chr&gt;   &lt;chr&gt;    \n1 B10010_002  Estimate!!Median family income in the past 12 m… Median… tract    \n2 B10010_003  Estimate!!Median family income in the past 12 m… Median… tract    \n3 B19013A_001 Estimate!!Median household income in the past 1… Median… tract    \n4 B19013B_001 Estimate!!Median household income in the past 1… Median… tract    \n5 B19013C_001 Estimate!!Median household income in the past 1… Median… tract    \n6 B19013D_001 Estimate!!Median household income in the past 1… Median… tract    \n\n# Alternative: search by concept\nincome_concept &lt;- acs_vars_2022 %&gt;%\n  filter(str_detect(concept, \"Median Household Income\"))\n\nhead(income_concept)\n\n# A tibble: 6 × 4\n  name        label                                            concept geography\n  &lt;chr&gt;       &lt;chr&gt;                                            &lt;chr&gt;   &lt;chr&gt;    \n1 B19013A_001 Estimate!!Median household income in the past 1… Median… tract    \n2 B19013B_001 Estimate!!Median household income in the past 1… Median… tract    \n3 B19013C_001 Estimate!!Median household income in the past 1… Median… tract    \n4 B19013D_001 Estimate!!Median household income in the past 1… Median… tract    \n5 B19013E_001 Estimate!!Median household income in the past 1… Median… county   \n6 B19013F_001 Estimate!!Median household income in the past 1… Median… tract    \n\n\nPattern Recognition: Median household income is typically B19013_001\n\n\n0.4 Search for Age Variables\nYour Task: Find median age variables.\n[write the code below - first add a code chunk]\n\n\n0.5 Advanced Search Techniques\nYour Task: Learn more sophisticated search methods.\n\n# Search for multiple terms at once\nhousing_vars &lt;- acs_vars_2022 %&gt;%\n  filter(str_detect(label, \"[Mm]edian.*(rent|value)\"))\n\nprint(\"Housing cost variables:\")\n\n[1] \"Housing cost variables:\"\n\nhead(housing_vars, 10)\n\n# A tibble: 10 × 4\n   name         label                                          concept geography\n   &lt;chr&gt;        &lt;chr&gt;                                          &lt;chr&gt;   &lt;chr&gt;    \n 1 B07002PR_004 Estimate!!Median age --!!Total:!!Moved from d… Median… &lt;NA&gt;     \n 2 B07002_004   Estimate!!Median age --!!Total:!!Moved from d… Median… tract    \n 3 B07002_005   Estimate!!Median age --!!Total:!!Moved from d… Median… tract    \n 4 B07011PR_004 Estimate!!Median income in the past 12 months… Median… &lt;NA&gt;     \n 5 B07011_004   Estimate!!Median income in the past 12 months… Median… tract    \n 6 B07011_005   Estimate!!Median income in the past 12 months… Median… tract    \n 7 B07402PR_004 Estimate!!Median age --!!Total living in area… Median… &lt;NA&gt;     \n 8 B07402_004   Estimate!!Median age --!!Total living in area… Median… county   \n 9 B07402_005   Estimate!!Median age --!!Total living in area… Median… county   \n10 B07411PR_004 Estimate!!Median income in the past 12 months… Median… &lt;NA&gt;     \n\n# Search excluding certain terms\nincome_not_family &lt;- acs_vars_2022 %&gt;%\n  filter(str_detect(label, \"[Mm]edian.*income\") & \n         !str_detect(label, \"family\"))\n\nprint(\"Income variables (not family income):\")\n\n[1] \"Income variables (not family income):\"\n\nhead(income_not_family)\n\n# A tibble: 6 × 4\n  name         label                                           concept geography\n  &lt;chr&gt;        &lt;chr&gt;                                           &lt;chr&gt;   &lt;chr&gt;    \n1 B06011PR_001 Estimate!!Median income in the past 12 months … Median… &lt;NA&gt;     \n2 B06011PR_002 Estimate!!Median income in the past 12 months … Median… &lt;NA&gt;     \n3 B06011PR_003 Estimate!!Median income in the past 12 months … Median… &lt;NA&gt;     \n4 B06011PR_004 Estimate!!Median income in the past 12 months … Median… &lt;NA&gt;     \n5 B06011PR_005 Estimate!!Median income in the past 12 months … Median… &lt;NA&gt;     \n6 B06011_001   Estimate!!Median income in the past 12 months … Median… tract    \n\n# Case-insensitive search using regex\neducation_vars &lt;- acs_vars_2022 %&gt;%\n  filter(str_detect(label, regex(\"bachelor\", ignore_case = TRUE)))\n\nprint(\"Education variables:\")\n\n[1] \"Education variables:\"\n\nhead(education_vars, 5)\n\n# A tibble: 5 × 4\n  name         label                                           concept geography\n  &lt;chr&gt;        &lt;chr&gt;                                           &lt;chr&gt;   &lt;chr&gt;    \n1 B06009PR_005 Estimate!!Total:!!Bachelor's degree             Place … &lt;NA&gt;     \n2 B06009PR_011 Estimate!!Total:!!Born in Puerto Rico:!!Bachel… Place … &lt;NA&gt;     \n3 B06009PR_017 Estimate!!Total:!!Born in the United States:!!… Place … &lt;NA&gt;     \n4 B06009PR_023 Estimate!!Total:!!Native; born elsewhere:!!Bac… Place … &lt;NA&gt;     \n5 B06009PR_029 Estimate!!Total:!!Foreign born:!!Bachelor's de… Place … &lt;NA&gt;     \n\n\n\n\n0.6 Interactive Exploration\nYour Task: Use RStudio’s viewer for easier searching.\n\n# Open the full variable list in RStudio viewer\n# This opens a searchable data table\nView(acs_vars_2022)\n\n# Pro tip: You can also search specific table groups\n# B01 = Age and Sex\n# B19 = Income  \n# B25 = Housing\ntable_b19 &lt;- acs_vars_2022 %&gt;%\n  filter(str_detect(name, \"^B19\"))  # ^ means \"starts with\"\n\nprint(\"All B19 (Income) table variables:\")\n\n[1] \"All B19 (Income) table variables:\"\n\nhead(table_b19, 10)\n\n# A tibble: 10 × 4\n   name        label                                concept            geography\n   &lt;chr&gt;       &lt;chr&gt;                                &lt;chr&gt;              &lt;chr&gt;    \n 1 B19001A_001 Estimate!!Total:                     Household Income … tract    \n 2 B19001A_002 Estimate!!Total:!!Less than $10,000  Household Income … tract    \n 3 B19001A_003 Estimate!!Total:!!$10,000 to $14,999 Household Income … tract    \n 4 B19001A_004 Estimate!!Total:!!$15,000 to $19,999 Household Income … tract    \n 5 B19001A_005 Estimate!!Total:!!$20,000 to $24,999 Household Income … tract    \n 6 B19001A_006 Estimate!!Total:!!$25,000 to $29,999 Household Income … tract    \n 7 B19001A_007 Estimate!!Total:!!$30,000 to $34,999 Household Income … tract    \n 8 B19001A_008 Estimate!!Total:!!$35,000 to $39,999 Household Income … tract    \n 9 B19001A_009 Estimate!!Total:!!$40,000 to $44,999 Household Income … tract    \n10 B19001A_010 Estimate!!Total:!!$45,000 to $49,999 Household Income … tract    \n\n\n\n\n0.7 Verify Your Variable Choices\nYour Task: Test your variables by getting a small sample of data.\n\n# Test the variables you found\ntest_vars &lt;- c(\n  total_pop = \"B01003_001\",      # Total population\n  median_income = \"B19013_001\",  # Median household income\n  median_age = \"B01002_001\"      # Median age\n)\n\n# Get data for just one state to test\ntest_data &lt;- get_acs(\n  geography = \"state\",\n  variables = test_vars,\n  state = \"PA\",\n  year = 2022\n)\n\n# Check that you got what you expected\ntest_data\n\n# A tibble: 3 × 5\n  GEOID NAME         variable        estimate   moe\n  &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt;\n1 42    Pennsylvania median_age          40.8   0.1\n2 42    Pennsylvania total_pop     12989208    NA  \n3 42    Pennsylvania median_income    73170   347  \n\n\n\n\n0.8 Common Variable Patterns\nReference guide for future use:\n\n# Common patterns to remember:\ncommon_variables &lt;- tribble(\n  ~concept, ~typical_code, ~description,\n  \"Total Population\", \"B01003_001\", \"Total population\",\n  \"Median Age\", \"B01002_001\", \"Median age of population\", \n  \"Median HH Income\", \"B19013_001\", \"Median household income\",\n  \"White Population\", \"B03002_003\", \"White alone population\",\n  \"Black Population\", \"B03002_004\", \"Black/African American alone\",\n  \"Hispanic Population\", \"B03002_012\", \"Hispanic or Latino population\",\n  \"Bachelor's Degree\", \"B15003_022\", \"Bachelor's degree or higher\",\n  \"Median Rent\", \"B25058_001\", \"Median contract rent\",\n  \"Median Home Value\", \"B25077_001\", \"Median value owner-occupied\"\n)\n\nprint(\"Common Census Variables:\")\n\n[1] \"Common Census Variables:\"\n\ncommon_variables\n\n# A tibble: 9 × 3\n  concept             typical_code description                  \n  &lt;chr&gt;               &lt;chr&gt;        &lt;chr&gt;                        \n1 Total Population    B01003_001   Total population             \n2 Median Age          B01002_001   Median age of population     \n3 Median HH Income    B19013_001   Median household income      \n4 White Population    B03002_003   White alone population       \n5 Black Population    B03002_004   Black/African American alone \n6 Hispanic Population B03002_012   Hispanic or Latino population\n7 Bachelor's Degree   B15003_022   Bachelor's degree or higher  \n8 Median Rent         B25058_001   Median contract rent         \n9 Median Home Value   B25077_001   Median value owner-occupied  \n\n\nKey Tips for Variable Hunting:\n\nStart with concepts - search for the topic you want (income, age, housing)\nLook for “Median” vs “Mean” - median is usually more policy-relevant\nCheck the universe - some variables are for “households,” others for “population”\nTest with small data before running large queries\nBookmark useful variables for future projects (type them in your weekly notes!)"
  },
  {
    "objectID": "exercise/week3_lab_exercise.html#exercise-1-single-variable-eda",
    "href": "exercise/week3_lab_exercise.html#exercise-1-single-variable-eda",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 1: Single Variable EDA",
    "text": "Exercise 1: Single Variable EDA\n\n1.1 Load and Inspect Data\n\n# Get county-level data for your state\ncounty_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    total_pop = \"B01003_001\",       # Total population\n    median_income = \"B19013_001\",   # Median household income\n    median_age = \"B01002_001\"       # Median age\n  ),\n  state = state_choice,\n  year = 2022,\n  output = \"wide\"\n)\n\n# Clean county names\ncounty_data &lt;- county_data %&gt;%\n  mutate(county_name = str_remove(NAME, paste0(\", \", state_choice)))\n\n# Basic inspection\nglimpse(county_data)\n\nRows: 67\nColumns: 9\n$ GEOID          &lt;chr&gt; \"42001\", \"42003\", \"42005\", \"42007\", \"42009\", \"42011\", \"…\n$ NAME           &lt;chr&gt; \"Adams County, Pennsylvania\", \"Allegheny County, Pennsy…\n$ total_popE     &lt;dbl&gt; 104604, 1245310, 65538, 167629, 47613, 428483, 122640, …\n$ total_popM     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ median_incomeE &lt;dbl&gt; 78975, 72537, 61011, 67194, 58337, 74617, 59386, 60650,…\n$ median_incomeM &lt;dbl&gt; 3334, 869, 2202, 1531, 2606, 1191, 2058, 2167, 1516, 21…\n$ median_ageE    &lt;dbl&gt; 43.8, 40.6, 47.0, 44.9, 47.3, 39.9, 42.9, 43.9, 44.0, 4…\n$ median_ageM    &lt;dbl&gt; 0.2, 0.1, 0.2, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, …\n$ county_name    &lt;chr&gt; \"Adams County, Pennsylvania\", \"Allegheny County, Pennsy…\n\n\n\n\n1.2 Explore Income Distribution\nYour Task: Create a histogram of median household income and describe what you see.\n\n# Create histogram of median income\nggplot(county_data) +\n  aes(x = median_incomeE) +\n  geom_histogram(bins = 15, fill = \"steelblue\", alpha = 0.7) +\n  labs(\n    title = \"Distribution of Median Household Income\",\n    x = \"Median Household Income ($)\",\n    y = \"Number of Counties\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = dollar)\n\n\n\n\n\n\n\n\n\n\n1.3 Box Plot for Outlier Detection\nYour Task: Create a boxplot to identify specific outlier counties.\n\n# Box plot to see outliers clearly\nggplot(county_data) +\n  aes(y = median_incomeE) +\n  geom_boxplot(fill = \"lightblue\", width = 0.5) +\n  labs(\n    title = \"Median Income Distribution with Outliers\",\n    y = \"Median Household Income ($)\"\n  ) +\n  theme_minimal() +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n# Identify the outlier counties\nincome_outliers &lt;- county_data %&gt;%\n  mutate(\n    Q1 = quantile(median_incomeE, 0.25, na.rm = TRUE),\n    Q3 = quantile(median_incomeE, 0.75, na.rm = TRUE),\n    IQR = Q3 - Q1,\n    outlier = median_incomeE &lt; (Q1 - 1.5 * IQR) | median_incomeE &gt; (Q3 + 1.5 * IQR)\n  ) %&gt;%\n  filter(outlier) %&gt;%\n  select(county_name, median_incomeE)\n\nprint(\"Outlier counties:\")\n\n[1] \"Outlier counties:\"\n\nincome_outliers\n\n# A tibble: 3 × 2\n  county_name                     median_incomeE\n  &lt;chr&gt;                                    &lt;dbl&gt;\n1 Bucks County, Pennsylvania              107826\n2 Chester County, Pennsylvania            118574\n3 Montgomery County, Pennsylvania         107441\n\n\n\n\n1.4 Challenge Exercise: Population Distribution\nYour Task: Create your own visualization of population distribution and identify outliers.\nRequirements:\n\nCreate a histogram of total population (total_popE)\nUse a different color than the income example (try “darkgreen” or “purple”)\nAdd appropriate labels and title\nCreate a boxplot to identify population outliers\nFind and list the 3 most populous and 3 least populous counties"
  },
  {
    "objectID": "exercise/week3_lab_exercise.html#exercise-2-two-variable-relationships",
    "href": "exercise/week3_lab_exercise.html#exercise-2-two-variable-relationships",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 2: Two Variable Relationships",
    "text": "Exercise 2: Two Variable Relationships\n\n2.1 Population vs Income Scatter Plot\nYour Task: Explore the relationship between population size and median income.\n\n# Basic scatter plot\nggplot(county_data) +\n  aes(x = total_popE, y = median_incomeE) +\n  geom_point() +\n  labs(\n    title = \"Population vs Median Income\",\n    x = \"Total Population\",\n    y = \"Median Household Income ($)\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n\n\n\n2.2 Add Trend Line and Labels\nYour Task: Improve the plot by adding a trend line and labeling interesting points.\n\n# Enhanced scatter plot with trend line\nggplot(county_data) +\n  aes(x = total_popE, y = median_incomeE) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"red\") +\n  labs(\n    title = \"Population vs Median Income in Pennsylvania Counties\",\n    subtitle = \"2018-2022 ACS 5-Year Estimates\",\n    x = \"Total Population\",\n    y = \"Median Household Income ($)\",\n    caption = \"Source: U.S. Census Bureau\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n# Calculate correlation\ncorrelation &lt;- cor(county_data$total_popE, county_data$median_incomeE, use = \"complete.obs\")\nprint(paste(\"Correlation coefficient:\", round(correlation, 3)))\n\n[1] \"Correlation coefficient: 0.457\"\n\n\n\n\n2.3 Deal with Skewed Data\nYour Task: The population data is highly skewed. Try a log transformation.\n\n# Log-transformed scatter plot\nggplot(county_data) +\n  aes(x = log(total_popE), y = median_incomeE) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  labs(\n    title = \"Log(Population) vs Median Income\",\n    x = \"Log(Total Population)\",\n    y = \"Median Household Income ($)\"\n  ) +\n  theme_minimal() +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n\nQuestion: Does the log transformation reveal a clearer relationship?\n\n\n2.4 Challenge Exercise: Age vs Income Relationship\nYour Task: Explore the relationship between median age and median income using different visualization techniques.\nRequirements:\n\nCreate a scatter plot with median age on x-axis and median income on y-axis\nUse red points (color = \"red\") with 50% transparency (alpha = 0.5)\nAdd a smooth trend line using method = \"loess\" instead of “lm”\nUse the “dark” theme (theme_dark())\nFormat the y-axis with dollar signs\nAdd a title that mentions both variables"
  },
  {
    "objectID": "exercise/week3_lab_exercise.html#exercise-3-data-quality-visualization",
    "href": "exercise/week3_lab_exercise.html#exercise-3-data-quality-visualization",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 3: Data Quality Visualization",
    "text": "Exercise 3: Data Quality Visualization\n\n3.1 Visualize Margins of Error\nYour Task: Create a visualization showing how data reliability varies across counties.\n\n# Calculate MOE percentages\ncounty_reliability &lt;- county_data %&gt;%\n  mutate(\n    income_moe_pct = (median_incomeM / median_incomeE) * 100,\n    pop_category = case_when(\n      total_popE &lt; 50000 ~ \"Small (&lt;50K)\",\n      total_popE &lt; 200000 ~ \"Medium (50K-200K)\",\n      TRUE ~ \"Large (200K+)\"\n    )\n  )\n\n# MOE by population size\nggplot(county_reliability) +\n  aes(x = total_popE, y = income_moe_pct) +\n  geom_point(alpha = 0.7) +\n  geom_hline(yintercept = 10, color = \"red\", linetype = \"dashed\") +\n  labs(\n    title = \"Data Reliability Decreases with Population Size\",\n    x = \"Total Population\",\n    y = \"Margin of Error (%)\",\n    caption = \"Red line = 10% reliability threshold\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = comma)\n\n\n\n\n\n\n\n\n\n\n3.2 Compare Reliability by County Size\nYour Task: Use box plots to compare MOE across county size categories.\n\n# Box plots by population category\nggplot(county_reliability) +\n  aes(x = pop_category, y = income_moe_pct, fill = pop_category) +\n  geom_boxplot() +\n  labs(\n    title = \"Data Reliability by County Size Category\",\n    x = \"Population Category\",\n    y = \"Margin of Error (%)\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove legend since x-axis is clear\n\n\n\n\n\n\n\n\n\n\n3.3 Challenge Exercise: Age Data Reliability\nYour Task: Analyze the reliability of median age data across counties.\nRequirements:\n\nCalculate MOE percentage for median age (median_ageM / median_ageE * 100)\nCreate a scatter plot showing population vs age MOE percentage\nUse purple points (color = \"purple\") with size = 2\nAdd a horizontal line at 5% MOE using geom_hline() with a blue dashed line\nUse theme_classic()instead of theme_minimal()\nCreate a boxplot comparing age MOE across the three population categories"
  },
  {
    "objectID": "exercise/week3_lab_exercise.html#exercise-4-multiple-variables-with-color-and-faceting",
    "href": "exercise/week3_lab_exercise.html#exercise-4-multiple-variables-with-color-and-faceting",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 4: Multiple Variables with Color and Faceting",
    "text": "Exercise 4: Multiple Variables with Color and Faceting\n\n4.1 Three-Variable Scatter Plot\nYour Task: Add median age as a color dimension to the population-income relationship.\n\n# Three-variable scatter plot\nggplot(county_data) +\n  aes(x = total_popE, y = median_incomeE, color = median_ageE) +\n  geom_point(size = 2, alpha = 0.7) +\n  scale_color_viridis_c(name = \"Median\\nAge\") +\n  labs(\n    title = \"Population, Income, and Age Patterns\",\n    x = \"Total Population\",\n    y = \"Median Household Income ($)\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n\n\n\n4.2 Create Categories for Faceting\nYour Task: Create age categories and use faceting to compare patterns.\n\n# Create age categories and faceted plot\ncounty_faceted &lt;- county_data %&gt;%\n  mutate(\n    age_category = case_when(\n      median_ageE &lt; 40 ~ \"Young (&lt; 40)\",\n      median_ageE &lt; 45 ~ \"Middle-aged (40-45)\",\n      TRUE ~ \"Older (45+)\"\n    )\n  )\n\nggplot(county_faceted) +\n  aes(x = total_popE, y = median_incomeE) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~age_category) +\n  labs(\n    title = \"Population-Income Relationship by Age Profile\",\n    x = \"Total Population\",\n    y = \"Median Income ($)\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n\nQuestion: Do the relationships between population and income differ by age profile?\nYour Task: Create a visualization using income categories and multiple aesthetic mappings.\nRequirements:\n\nCreate income categories: “Low” (&lt;$50k), “Middle” ($50k-$80k), “High” (&gt;$80k)\nMake a scatter plot with population (x) vs median age (y) - Color points by income category\nSize points by the margin of error for income (median_incomeM)\nUse the “Set2” color palette: scale_color_brewer(palette = \"Set2\") **note: you’ll need to load the RColorBrewer package for this`\nFacet by income category using facet_wrap()\nUse theme_bw() theme"
  },
  {
    "objectID": "exercise/week3_lab_exercise.html#exercise-5-data-joins-and-integration",
    "href": "exercise/week3_lab_exercise.html#exercise-5-data-joins-and-integration",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 5: Data Joins and Integration",
    "text": "Exercise 5: Data Joins and Integration\n\n5.1 Get Additional Census Data\nYour Task: Load educational attainment data and join it with our existing data.\n\n# Get educational attainment data\neducation_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    total_25plus = \"B15003_001\",    # Total population 25 years and over\n    bachelor_plus = \"B15003_022\"    # Bachelor's degree or higher\n  ),\n  state = state_choice,\n  year = 2022,\n  output = \"wide\"\n) %&gt;%\n  mutate(\n    pct_college = (bachelor_plusE / total_25plusE) * 100,\n    county_name = str_remove(NAME, paste0(\", \", state_choice))\n  ) %&gt;%\n  select(GEOID, county_name, pct_college)\n\n# Check the data\nhead(education_data)\n\n# A tibble: 6 × 3\n  GEOID county_name                    pct_college\n  &lt;chr&gt; &lt;chr&gt;                                &lt;dbl&gt;\n1 42001 Adams County, Pennsylvania           13.9 \n2 42003 Allegheny County, Pennsylvania       25.4 \n3 42005 Armstrong County, Pennsylvania       12.7 \n4 42007 Beaver County, Pennsylvania          18.3 \n5 42009 Bedford County, Pennsylvania          9.73\n6 42011 Berks County, Pennsylvania           17.2 \n\n\n\n\n5.2 Join the Datasets\nYour Task: Join the education data with our main county dataset.\n\n# Perform the join\ncombined_data &lt;- county_data %&gt;%\n  left_join(education_data, by = \"GEOID\")\n\n# Check the join worked\ncat(\"Original data rows:\", nrow(county_data), \"\\n\")\n\nOriginal data rows: 67 \n\ncat(\"Combined data rows:\", nrow(combined_data), \"\\n\")\n\nCombined data rows: 67 \n\ncat(\"Missing education data:\", sum(is.na(combined_data$pct_college)), \"\\n\")\n\nMissing education data: 0 \n\n# View the combined data\nhead(combined_data)\n\n# A tibble: 6 × 11\n  GEOID NAME     total_popE total_popM median_incomeE median_incomeM median_ageE\n  &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n1 42001 Adams C…     104604         NA          78975           3334        43.8\n2 42003 Alleghe…    1245310         NA          72537            869        40.6\n3 42005 Armstro…      65538         NA          61011           2202        47  \n4 42007 Beaver …     167629         NA          67194           1531        44.9\n5 42009 Bedford…      47613         NA          58337           2606        47.3\n6 42011 Berks C…     428483         NA          74617           1191        39.9\n# ℹ 4 more variables: median_ageM &lt;dbl&gt;, county_name.x &lt;chr&gt;,\n#   county_name.y &lt;chr&gt;, pct_college &lt;dbl&gt;\n\n\n\n\n5.3 Analyze the New Relationship\nYour Task: Explore the relationship between education and income.\n\n# Education vs Income scatter plot\nggplot(combined_data) +\n  aes(x = pct_college, y = median_incomeE) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  labs(\n    title = \"Education vs Income Across Counties\",\n    x = \"Percent with Bachelor's Degree or Higher\",\n    y = \"Median Household Income ($)\"\n  ) +\n  theme_minimal() +\n  scale_y_continuous(labels = dollar)\n\n\n\n\n\n\n\n# Calculate correlation\nedu_income_cor &lt;- cor(combined_data$pct_college, combined_data$median_incomeE, use = \"complete.obs\")\nprint(paste(\"Education-Income Correlation:\", round(edu_income_cor, 3)))\n\n[1] \"Education-Income Correlation: 0.811\"\n\n\n\n\n5.4 Get Housing Data and Triple Join\nYour Task: Add housing cost data to create a three-way analysis.\n\n# Get housing cost data\nhousing_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    median_rent = \"B25058_001\",     # Median contract rent\n    median_home_value = \"B25077_001\" # Median value of owner-occupied units\n  ),\n  state = state_choice,\n  year = 2022,\n  output = \"wide\"\n) %&gt;%\n  select(GEOID, median_rent = median_rentE, median_home_value = median_home_valueE)\n\n# Join all three datasets\nfull_data &lt;- combined_data %&gt;%\n  left_join(housing_data, by = \"GEOID\")\n\n# Create a housing affordability measure\nfull_data &lt;- full_data %&gt;%\n  mutate(\n    rent_to_income = (median_rent * 12) / median_incomeE * 100,\n    income_category = case_when(\n      median_incomeE &lt; 50000 ~ \"Low Income\",\n      median_incomeE &lt; 80000 ~ \"Middle Income\",\n      TRUE ~ \"High Income\"\n    )\n  )\n\nhead(full_data)\n\n# A tibble: 6 × 15\n  GEOID NAME     total_popE total_popM median_incomeE median_incomeM median_ageE\n  &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n1 42001 Adams C…     104604         NA          78975           3334        43.8\n2 42003 Alleghe…    1245310         NA          72537            869        40.6\n3 42005 Armstro…      65538         NA          61011           2202        47  \n4 42007 Beaver …     167629         NA          67194           1531        44.9\n5 42009 Bedford…      47613         NA          58337           2606        47.3\n6 42011 Berks C…     428483         NA          74617           1191        39.9\n# ℹ 8 more variables: median_ageM &lt;dbl&gt;, county_name.x &lt;chr&gt;,\n#   county_name.y &lt;chr&gt;, pct_college &lt;dbl&gt;, median_rent &lt;dbl&gt;,\n#   median_home_value &lt;dbl&gt;, rent_to_income &lt;dbl&gt;, income_category &lt;chr&gt;\n\n\n\n\n5.5 Advanced Multi-Variable Analysis\nYour Task: Create a comprehensive visualization showing multiple relationships.\n\n# Complex multi-variable plot\nggplot(full_data) +\n  aes(x = pct_college, y = rent_to_income, \n      color = income_category, size = total_popE) +\n  geom_point(alpha = 0.7) +\n  labs(\n    title = \"Education, Housing Affordability, and Income Patterns\",\n    subtitle = \"Larger points = larger population\",\n    x = \"Percent with Bachelor's Degree or Higher\",\n    y = \"Annual Rent as % of Median Income\",\n    color = \"Income Category\",\n    size = \"Population\"\n  ) +\n  theme_minimal() +\n  guides(size = guide_legend(override.aes = list(alpha = 1)))"
  },
  {
    "objectID": "exercise/week3_lab_exercise.html#exercise-6-publication-ready-visualization",
    "href": "exercise/week3_lab_exercise.html#exercise-6-publication-ready-visualization",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 6: Publication-Ready Visualization",
    "text": "Exercise 6: Publication-Ready Visualization\n\n6.1 Create a Policy-Focused Visualization\nYour Task: Combine multiple visualizations to tell a more complete story about county characteristics.\n\n# Create a multi-panel figure\nlibrary(patchwork)  # For combining plots\n\n# Plot 1: Income distribution\np1 &lt;- ggplot(full_data) +\n  aes(x = median_incomeE) +\n  geom_histogram(bins = 15, fill = \"steelblue\", alpha = 0.7) +\n  labs(title = \"A) Income Distribution\", \n       x = \"Median Income ($)\", y = \"Counties\") +\n  scale_x_continuous(labels = dollar) +\n  theme_minimal()\n\n# Plot 2: Education vs Income\np2 &lt;- ggplot(full_data) +\n  aes(x = pct_college, y = median_incomeE) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"B) Education vs Income\",\n       x = \"% College Educated\", y = \"Median Income ($)\") +\n  scale_y_continuous(labels = dollar) +\n  theme_minimal()\n\n# Plot 3: Housing affordability by income category\np3 &lt;- ggplot(full_data) +\n  aes(x = income_category, y = rent_to_income, fill = income_category) +\n  geom_boxplot() +\n  labs(title = \"C) Housing Affordability by Income\",\n       x = \"Income Category\", y = \"Rent as % of Income\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n# Plot 4: Data reliability by population\np4 &lt;- ggplot(county_reliability) +\n  aes(x = total_popE, y = income_moe_pct) +\n  geom_point(alpha = 0.7) +\n  geom_hline(yintercept = 10, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"D) Data Reliability\",\n       x = \"Population\", y = \"MOE (%)\") +\n  scale_x_continuous(labels = comma) +\n  theme_minimal()\n\n# Combine all plots\ncombined_plot &lt;- (p1 | p2) / (p3 | p4)\ncombined_plot + plot_annotation(\n  title = \"Pennsylvania County Analysis: Income, Education, and Housing Patterns\",\n  caption = \"Source: American Community Survey 2018-2022\"\n)"
  },
  {
    "objectID": "exercise/week3_lab_exercise.html#exercise-7-ethical-data-communication---implementing-research-recommendations",
    "href": "exercise/week3_lab_exercise.html#exercise-7-ethical-data-communication---implementing-research-recommendations",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Exercise 7: Ethical Data Communication - Implementing Research Recommendations",
    "text": "Exercise 7: Ethical Data Communication - Implementing Research Recommendations\nBackground: Research by Jurjevich et al. (2018) found that only 27% of planners warn users about unreliable ACS data, violating AICP ethical standards. In this exercise, you’ll practice the five research-based guidelines for ethical ACS data communication.\n\n7.1 Create Professional Data Tables with Uncertainty\nYour Task: Follow the Jurjevich et al. guidelines to create an ethical data presentation.\n\n# Get comprehensive data for ethical analysis\nethical_demo_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    median_income = \"B19013_001\",   # Median household income\n    total_25plus = \"B15003_001\",    # Total population 25 years and over\n    bachelor_plus = \"B15003_022\",   # Bachelor's degree or higher\n    total_pop = \"B01003_001\"        # Total population\n  ),\n  state = state_choice,\n  year = 2022,\n  output = \"wide\"\n) %&gt;%\n  mutate(\n    # Calculate derived statistics\n    pct_college = (bachelor_plusE / total_25plusE) * 100,\n    \n    # Calculate MOE for percentage using error propagation\n    pct_college_moe = pct_college * sqrt((bachelor_plusM/bachelor_plusE)^2 + (total_25plusM/total_25plusE)^2),\n    \n    # Calculate coefficient of variation for all key variables\n    income_cv = (median_incomeM / median_incomeE) * 100,\n    education_cv = (pct_college_moe / pct_college) * 100,\n    \n    # Create reliability categories based on CV\n    income_reliability = case_when(\n      income_cv &lt; 12 ~ \"High\",\n      income_cv &lt;= 40 ~ \"Moderate\", \n      TRUE ~ \"Low\"\n    ),\n    \n    education_reliability = case_when(\n      education_cv &lt; 12 ~ \"High\",\n      education_cv &lt;= 40 ~ \"Moderate\",\n      TRUE ~ \"Low\"\n    ),\n    \n    # Create color coding for reliability\n    income_color = case_when(\n      income_reliability == \"High\" ~ \"🟢\",\n      income_reliability == \"Moderate\" ~ \"🟡\",\n      TRUE ~ \"🔴\"\n    ),\n    \n    education_color = case_when(\n      education_reliability == \"High\" ~ \"🟢\",\n      education_reliability == \"Moderate\" ~ \"🟡\", \n      TRUE ~ \"🔴\"\n    ),\n    \n    # Clean county names\n    county_name = str_remove(NAME, paste0(\", \", state_choice))\n  )\n\n# Create ethical data table focusing on least reliable estimates\nethical_data_table &lt;- ethical_demo_data %&gt;%\n  select(county_name, median_incomeE, median_incomeM, income_cv, income_color,\n         pct_college, pct_college_moe, education_cv, education_color) %&gt;%\n  arrange(desc(income_cv)) %&gt;%  # Show least reliable first\n  slice_head(n = 10)\n\n# Create professional table following guidelines\nlibrary(knitr)\nlibrary(kableExtra)\n\nethical_data_table %&gt;%\n  select(county_name, median_incomeE, median_incomeM, income_cv, income_color) %&gt;%\n  kable(\n    col.names = c(\"County\", \"Median Income\", \"Margin of Error\", \n                  \"CV (%)\", \"Reliability\"),\n    caption = \"Pennsylvania Counties: Median Household Income with Statistical Uncertainty\",\n    format.args = list(big.mark = \",\")\n  ) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %&gt;%\n  footnote(\n    general = c(\"Coefficient of Variation (CV) indicates reliability:\",\n                \"🟢 High reliability (CV &lt; 12%)\",\n                \"🟡 Moderate reliability (CV 12-40%)\", \n                \"🔴 Low reliability (CV &gt; 40%)\",\n                \"Following Jurjevich et al. (2018) research recommendations\",\n                \"Source: American Community Survey 2018-2022 5-Year Estimates\"),\n    general_title = \"Notes:\"\n  )\n\n\nPennsylvania Counties: Median Household Income with Statistical Uncertainty\n\n\nCounty\nMedian Income\nMargin of Error\nCV (%)\nReliability\n\n\n\n\nForest County, Pennsylvania\n46,188\n4,612\n9.985278\n🟢 |\n\n\nSullivan County, Pennsylvania\n62,910\n5,821\n9.252901\n🟢 |\n\n\nUnion County, Pennsylvania\n64,914\n4,753\n7.321995\n🟢 |\n\n\nMontour County, Pennsylvania\n72,626\n5,146\n7.085617\n🟢 |\n\n\nElk County, Pennsylvania\n61,672\n4,091\n6.633480\n🟢 |\n\n\nGreene County, Pennsylvania\n66,283\n4,247\n6.407374\n🟢 |\n\n\nCameron County, Pennsylvania\n46,186\n2,605\n5.640237\n🟢 |\n\n\nSnyder County, Pennsylvania\n65,914\n3,666\n5.561793\n🟢 |\n\n\nCarbon County, Pennsylvania\n64,538\n3,424\n5.305402\n🟢 |\n\n\nWarren County, Pennsylvania\n57,925\n3,005\n5.187743\n🟢 |\n\n\n\nNotes:\n\n\n\n\n\n\n Coefficient of Variation (CV) indicates reliability:\n\n\n\n\n\n\n 🟢 High reliability (CV &lt; 12%)\n\n\n\n\n\n\n 🟡 Moderate reliability (CV 12-40%)\n\n\n\n\n\n\n 🔴 Low reliability (CV &gt; 40%)\n\n\n\n\n\n\n Following Jurjevich et al. (2018) research recommendations\n\n\n\n\n\n\n Source: American Community Survey 2018-2022 5-Year Estimates\n\n\n\n\n\n\n\n\n\n\n\n\n7.3 Now try Census Tracts\n\n# Get census tract poverty data for Philadelphia\nphilly_poverty &lt;- get_acs(\n    geography = \"tract\",\n    variables = c(\n      poverty_pop = \"B17001_001\",     \n      poverty_below = \"B17001_002\"    \n    ),\n    state = \"PA\",\n    county = \"101\",\n    year = 2022,\n    output = \"wide\"\n  ) %&gt;%\n  filter(poverty_popE &gt; 0) %&gt;%  # Remove tracts with no poverty data\n  mutate(\n    # Calculate poverty rate and its MOE\n    poverty_rate = (poverty_belowE / poverty_popE) * 100,\n    \n    # MOE for derived percentage using error propagation\n    poverty_rate_moe = poverty_rate * sqrt((poverty_belowM/poverty_belowE)^2 + (poverty_popM/poverty_popE)^2),\n    \n    # Coefficient of variation\n    poverty_cv = (poverty_rate_moe / poverty_rate) * 100,\n    \n    # Reliability assessment\n    reliability = case_when(\n      poverty_cv &lt; 12 ~ \"High\",\n      poverty_cv &lt;= 40 ~ \"Moderate\",\n      poverty_cv &lt;= 75 ~ \"Low\",\n      TRUE ~ \"Very Low\"\n    ),\n    \n    # Color coding\n    reliability_color = case_when(\n      reliability == \"High\" ~ \"🟢\",\n      reliability == \"Moderate\" ~ \"🟡\",\n      reliability == \"Low\" ~ \"🟠\",\n      TRUE ~ \"🔴\"\n    ),\n    \n    # Population size categories\n    pop_category = case_when(\n      poverty_popE &lt; 500 ~ \"Very Small (&lt;500)\",\n      poverty_popE &lt; 1000 ~ \"Small (500-1000)\",\n      poverty_popE &lt; 1500 ~ \"Medium (1000-1500)\",\n      TRUE ~ \"Large (1500+)\"\n    )\n  )\n\n# Check the data quality crisis at tracts\nreliability_summary &lt;- philly_poverty %&gt;%\n  count(reliability) %&gt;%\n  mutate(\n    percentage = round(n / sum(n) * 100, 1),\n    total_bg = sum(n)\n  )\n\nprint(\"Philadelphia Census Tract Poverty Data Reliability:\")\n\n[1] \"Philadelphia Census Tract Poverty Data Reliability:\"\n\nreliability_summary %&gt;%\n  kable(\n    col.names = c(\"Data Quality\", \"Number of Tracts\", \"Percentage\", \"Total\"),\n    caption = \"The Data Quality Crisis: Philadelphia Census Tract Poverty Estimates\"\n  ) %&gt;%\n  kable_styling()\n\n\nThe Data Quality Crisis: Philadelphia Census Tract Poverty Estimates\n\n\nData Quality\nNumber of Tracts\nPercentage\nTotal\n\n\n\n\nLow\n295\n75.8\n389\n\n\nModerate\n53\n13.6\n389\n\n\nVery Low\n41\n10.5\n389\n\n\n\n\n\n\n# Show the most problematic estimates (following Guideline 3: provide context)\nworst_estimates &lt;- philly_poverty %&gt;%\n  filter(reliability %in% c(\"Low\", \"Very Low\")) %&gt;%\n  arrange(desc(poverty_cv)) %&gt;%\n  slice_head(n = 10)\n\nworst_estimates %&gt;%\n  select(GEOID, poverty_rate, poverty_rate_moe, poverty_cv, reliability_color, poverty_popE) %&gt;%\n  kable(\n    col.names = c(\"Tract\", \"Poverty Rate (%)\", \"MOE\", \"CV (%)\", \"Quality\", \"Pop Size\"),\n    caption = \"Guideline 3: Tracts with Least Reliable Poverty Estimates\",\n    digits = c(0, 1, 1, 1, 0, 0)\n  ) %&gt;%\n  kable_styling() %&gt;%\n  footnote(\n    general = c(\"These estimates should NOT be used for policy decisions\",\n                \"CV &gt; 75% indicates very low reliability\",\n                \"Recommend aggregation or alternative data sources\")\n  )\n\n\nGuideline 3: Tracts with Least Reliable Poverty Estimates\n\n\nTract\nPoverty Rate (%)\nMOE\nCV (%)\nQuality\nPop Size\n\n\n\n\n42101989100\n15.8\n45.2\n286.1\n🔴 |\n38|\n\n\n42101000101\n0.7\n1.1\n157.9\n🔴 |\n1947|\n\n\n42101980200\n37.9\n45.2\n119.4\n🔴 |\n66|\n\n\n42101023100\n3.8\n4.5\n119.4\n🔴 |\n1573|\n\n\n42101025600\n1.7\n2.0\n114.2\n🔴 |\n2642|\n\n\n42101014202\n1.7\n1.8\n107.0\n🔴 |\n2273|\n\n\n42101000403\n6.6\n6.7\n101.8\n🔴 |\n1047|\n\n\n42101026100\n4.7\n4.4\n95.0\n🔴 |\n2842|\n\n\n42101036502\n4.9\n4.7\n94.9\n🔴 |\n4284|\n\n\n42101032000\n21.8\n20.6\n94.8\n🔴 |\n7873|\n\n\n\nNote: \n\n\n\n\n\n\n\n These estimates should NOT be used for policy decisions\n\n\n\n\n\n\n\n CV &gt; 75% indicates very low reliability\n\n\n\n\n\n\n\n Recommend aggregation or alternative data sources"
  },
  {
    "objectID": "exercise/week3_lab_exercise.html#key-references-and-acknowledgments",
    "href": "exercise/week3_lab_exercise.html#key-references-and-acknowledgments",
    "title": "Week 3 In-Class Lab: Data Visualization and EDA",
    "section": "Key References and Acknowledgments",
    "text": "Key References and Acknowledgments\nJurjevich, J. R., Griffin, A. L., Spielman, S. E., Folch, D. C., Merrick, M., & Nagle, N. N. (2018). Navigating statistical uncertainty: How urban and regional planners understand and work with American community survey (ACS) data for guiding policy. Journal of the American Planning Association, 84(2), 112-126.\nWalker, K. (2023). Analyzing US Census Data: Methods, Maps, and Models in R. Available at: https://walker-data.com/census-r/\nAI Acknowledgments: This lab was developed with coding assistance from Claude AI. I have run, reviewed, and edited the final version. Any remaining errors are my own."
  },
  {
    "objectID": "labs/lab_0/lab0_template.html",
    "href": "labs/lab_0/lab0_template.html",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "",
    "text": "Welcome to your first lab! In this (not graded) assignment, you’ll practice the fundamental dplyr operations I overviewed in class using car sales data. This lab will help you get comfortable with:\n\nBasic data exploration\nColumn selection and manipulation\n\nCreating new variables\nFiltering data\nGrouping and summarizing\n\nInstructions: Copy this template into your portfolio repository under a lab_0/ folder, then complete each section with your code and answers. You will write the code under the comment section in each chunk. Be sure to also copy the data folder into your lab_0 folder."
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#data-structure-exploration",
    "href": "labs/lab_0/lab0_template.html#data-structure-exploration",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "1.1 Data Structure Exploration",
    "text": "1.1 Data Structure Exploration\nExplore the structure of your data and answer these questions:\n\n# Use glimpse() to see the data structure\n\nglimpse (car_data)\n\nRows: 50,000\nColumns: 7\n$ Manufacturer          &lt;chr&gt; \"Ford\", \"Porsche\", \"Ford\", \"Toyota\", \"VW\", \"Ford…\n$ Model                 &lt;chr&gt; \"Fiesta\", \"718 Cayman\", \"Mondeo\", \"RAV4\", \"Polo\"…\n$ `Engine size`         &lt;dbl&gt; 1.0, 4.0, 1.6, 1.8, 1.0, 1.4, 1.8, 1.4, 1.2, 2.0…\n$ `Fuel type`           &lt;chr&gt; \"Petrol\", \"Petrol\", \"Diesel\", \"Hybrid\", \"Petrol\"…\n$ `Year of manufacture` &lt;dbl&gt; 2002, 2016, 2014, 1988, 2006, 2018, 2010, 2015, …\n$ Mileage               &lt;dbl&gt; 127300, 57850, 39190, 210814, 127869, 33603, 866…\n$ Price                 &lt;dbl&gt; 3074, 49704, 24072, 1705, 4101, 29204, 14350, 30…\n\n# Check the column names\nnames(car_data)\n\n[1] \"Manufacturer\"        \"Model\"               \"Engine size\"        \n[4] \"Fuel type\"           \"Year of manufacture\" \"Mileage\"            \n[7] \"Price\"              \n\n# Look at the first few rows\nhead(car_data)\n\n# A tibble: 6 × 7\n  Manufacturer Model     `Engine size` `Fuel type` `Year of manufacture` Mileage\n  &lt;chr&gt;        &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;                       &lt;dbl&gt;   &lt;dbl&gt;\n1 Ford         Fiesta              1   Petrol                       2002  127300\n2 Porsche      718 Caym…           4   Petrol                       2016   57850\n3 Ford         Mondeo              1.6 Diesel                       2014   39190\n4 Toyota       RAV4                1.8 Hybrid                       1988  210814\n5 VW           Polo                1   Petrol                       2006  127869\n6 Ford         Focus               1.4 Petrol                       2018   33603\n# ℹ 1 more variable: Price &lt;dbl&gt;\n\n\nQuestions to answer: - How many rows and columns does the dataset have? - What types of variables do you see (numeric, character, etc.)? - Are there any column names that might cause problems? Why?\nYour answers: - Rows: 6 - Columns: 7\n- Variable types: categorical (nominal) variables - Problematic names: Engine size, Fuel type, Year of manufacture"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#tibble-vs-data-frame",
    "href": "labs/lab_0/lab0_template.html#tibble-vs-data-frame",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "1.2 Tibble vs Data Frame",
    "text": "1.2 Tibble vs Data Frame\nCompare how tibbles and data frames display:\n\n# Look at the tibble version (what we have)\nhead(car_data)\n\n# A tibble: 6 × 7\n  Manufacturer Model     `Engine size` `Fuel type` `Year of manufacture` Mileage\n  &lt;chr&gt;        &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;                       &lt;dbl&gt;   &lt;dbl&gt;\n1 Ford         Fiesta              1   Petrol                       2002  127300\n2 Porsche      718 Caym…           4   Petrol                       2016   57850\n3 Ford         Mondeo              1.6 Diesel                       2014   39190\n4 Toyota       RAV4                1.8 Hybrid                       1988  210814\n5 VW           Polo                1   Petrol                       2006  127869\n6 Ford         Focus               1.4 Petrol                       2018   33603\n# ℹ 1 more variable: Price &lt;dbl&gt;\n\n# Convert to regular data frame and display\ncar_df &lt;- as.data.frame(car_data)\nhead(car_df)\n\n  Manufacturer      Model Engine size Fuel type Year of manufacture Mileage\n1         Ford     Fiesta         1.0    Petrol                2002  127300\n2      Porsche 718 Cayman         4.0    Petrol                2016   57850\n3         Ford     Mondeo         1.6    Diesel                2014   39190\n4       Toyota       RAV4         1.8    Hybrid                1988  210814\n5           VW       Polo         1.0    Petrol                2006  127869\n6         Ford      Focus         1.4    Petrol                2018   33603\n  Price\n1  3074\n2 49704\n3 24072\n4  1705\n5  4101\n6 29204\n\n\nQuestion: What differences do you notice in how they print?\nYour answer: Tibbles print only the rows and columns that fit on the screen, display column types, and show the total number of rows and columns. In contrast, data frames print more rows by default and do not display column type information, making them less readable."
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#selecting-columns",
    "href": "labs/lab_0/lab0_template.html#selecting-columns",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "2.1 Selecting Columns",
    "text": "2.1 Selecting Columns\nPractice selecting different combinations of columns:\n\n# Select just Model and Mileage columns\nhead(select(car_df, Model, Mileage))\n\n       Model Mileage\n1     Fiesta  127300\n2 718 Cayman   57850\n3     Mondeo   39190\n4       RAV4  210814\n5       Polo  127869\n6      Focus   33603\n\n# Select Manufacturer, Price, and Fuel type\nhead(select(car_df, Manufacturer, Price, 'Fuel type'))\n\n  Manufacturer Price Fuel type\n1         Ford  3074    Petrol\n2      Porsche 49704    Petrol\n3         Ford 24072    Diesel\n4       Toyota  1705    Hybrid\n5           VW  4101    Petrol\n6         Ford 29204    Petrol\n\n# Challenge: Select all columns EXCEPT Engine Size\nhead(select(car_df, -'Engine size'))\n\n  Manufacturer      Model Fuel type Year of manufacture Mileage Price\n1         Ford     Fiesta    Petrol                2002  127300  3074\n2      Porsche 718 Cayman    Petrol                2016   57850 49704\n3         Ford     Mondeo    Diesel                2014   39190 24072\n4       Toyota       RAV4    Hybrid                1988  210814  1705\n5           VW       Polo    Petrol                2006  127869  4101\n6         Ford      Focus    Petrol                2018   33603 29204"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#renaming-columns",
    "href": "labs/lab_0/lab0_template.html#renaming-columns",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "2.2 Renaming Columns",
    "text": "2.2 Renaming Columns\nLet’s fix a problematic column name:\n\n# Rename 'Year of manufacture' to year\ncar_df &lt;- rename(car_df, year = `Year of manufacture`)\n\n# Check that it worked\nnames (car_df)\n\n[1] \"Manufacturer\" \"Model\"        \"Engine size\"  \"Fuel type\"    \"year\"        \n[6] \"Mileage\"      \"Price\"       \n\n\nQuestion: Why did we need backticks around Year of manufacture but not around year?\nYour answer: Backticks are required for Year of manufacture because it contains spaces and is not a valid R identifier. The column name year follows R’s naming rules and can be referenced directly without backticks."
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#calculate-car-age",
    "href": "labs/lab_0/lab0_template.html#calculate-car-age",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "3.1 Calculate Car Age",
    "text": "3.1 Calculate Car Age\n\n# Create an 'age' column (2025 minus year of manufacture)\ncar_df &lt;- mutate(\n  car_df,\n  age = 2025 - year,\n  mileage_per_year = Mileage / age\n)\n\n# Create a mileage_per_year column  \n\n\n# Look at your new columns\n#select(car_data, Model, year, age, Mileage, mileage_per_year)"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#categorize-cars",
    "href": "labs/lab_0/lab0_template.html#categorize-cars",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "3.2 Categorize Cars",
    "text": "3.2 Categorize Cars\n\n# Create a price_category column where if price is &lt; 15000, its is coded as budget, between 15000 and 30000 is midrange and greater than 30000 is mid-range (use case_when)\ncar_df &lt;- mutate(\n  car_df,\n  price_category = case_when(\n    Price &lt; 15000 ~ \"budget\",\n    Price &gt;= 15000 & Price &lt;= 30000 ~ \"midrange\",\n    Price &gt; 30000 ~ \"premium\"\n  )\n)\n\n# Check your categories select the new column and show it\nhead(select(car_df, Model, Price, price_category))\n\n       Model Price price_category\n1     Fiesta  3074         budget\n2 718 Cayman 49704        premium\n3     Mondeo 24072       midrange\n4       RAV4  1705         budget\n5       Polo  4101         budget\n6      Focus 29204       midrange"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#basic-filtering",
    "href": "labs/lab_0/lab0_template.html#basic-filtering",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "4.1 Basic Filtering",
    "text": "4.1 Basic Filtering\n\n# Find all Toyota cars\nhead(filter(car_df, Manufacturer == \"Toyota\"))\n\n  Manufacturer Model Engine size Fuel type year Mileage Price age\n1       Toyota  RAV4         1.8    Hybrid 1988  210814  1705  37\n2       Toyota Prius         1.4    Hybrid 2015   30663 30297  10\n3       Toyota  RAV4         2.2    Petrol 2007   79393 16026  18\n4       Toyota Yaris         1.4    Petrol 1998   97286  4046  27\n5       Toyota  RAV4         2.4    Hybrid 2003  117425 11667  22\n6       Toyota Yaris         1.2    Petrol 1992  245990   720  33\n  mileage_per_year price_category\n1         5697.676         budget\n2         3066.300        premium\n3         4410.722       midrange\n4         3603.185         budget\n5         5337.500         budget\n6         7454.242         budget\n\n# Find cars with mileage less than 30,000\nhead(filter(car_df, Mileage &lt; 30000))\n\n  Manufacturer      Model Engine size Fuel type year Mileage Price age\n1       Toyota       RAV4         2.0    Hybrid 2018   28381 52671   7\n2           VW       Golf         2.0    Petrol 2020   18985 36387   5\n3          BMW         M5         4.0    Petrol 2017   22759 97758   8\n4       Toyota       RAV4         2.4    Petrol 2018   24588 49125   7\n5           VW       Golf         2.0    Hybrid 2018   25017 36957   7\n6      Porsche 718 Cayman         2.4    Petrol 2021   14070 69526   4\n  mileage_per_year price_category\n1         4054.429        premium\n2         3797.000        premium\n3         2844.875        premium\n4         3512.571        premium\n5         3573.857        premium\n6         3517.500        premium\n\n# Find luxury cars (from price category) with low mileage\nhead(filter(car_df, price_category == \"premium\" & Mileage &lt; 30000))\n\n  Manufacturer      Model Engine size Fuel type year Mileage Price age\n1       Toyota       RAV4         2.0    Hybrid 2018   28381 52671   7\n2           VW       Golf         2.0    Petrol 2020   18985 36387   5\n3          BMW         M5         4.0    Petrol 2017   22759 97758   8\n4       Toyota       RAV4         2.4    Petrol 2018   24588 49125   7\n5           VW       Golf         2.0    Hybrid 2018   25017 36957   7\n6      Porsche 718 Cayman         2.4    Petrol 2021   14070 69526   4\n  mileage_per_year price_category\n1         4054.429        premium\n2         3797.000        premium\n3         2844.875        premium\n4         3512.571        premium\n5         3573.857        premium\n6         3517.500        premium"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#multiple-conditions",
    "href": "labs/lab_0/lab0_template.html#multiple-conditions",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "4.2 Multiple Conditions",
    "text": "4.2 Multiple Conditions\n\n# Find cars that are EITHER Honda OR Nissan\ncar_df %&gt;%\n  filter(Manufacturer == \"Honda\" | Manufacturer == \"Nissan\") %&gt;%\n  head()\n\n [1] Manufacturer     Model            Engine size      Fuel type       \n [5] year             Mileage          Price            age             \n [9] mileage_per_year price_category  \n&lt;0 rows&gt; (or 0-length row.names)\n\n# Find cars with price between $20,000 and $35,000\ncar_df %&gt;%\n  filter(Price &gt;= 20000 & Price &lt;= 35000) %&gt;%\n  head()\n\n  Manufacturer  Model Engine size Fuel type year Mileage Price age\n1         Ford Mondeo         1.6    Diesel 2014   39190 24072  11\n2         Ford  Focus         1.4    Petrol 2018   33603 29204   7\n3       Toyota  Prius         1.4    Hybrid 2015   30663 30297  10\n4       Toyota  Prius         1.4    Hybrid 2016   43893 29946   9\n5       Toyota  Prius         1.4    Hybrid 2016   43130 30085   9\n6           VW Passat         1.6    Petrol 2016   64344 23641   9\n  mileage_per_year price_category\n1         3562.727       midrange\n2         4800.429       midrange\n3         3066.300        premium\n4         4877.000       midrange\n5         4792.222        premium\n6         7149.333       midrange\n\n# Find diesel cars less than 10 years old\ndiesel_under_10 &lt;- car_df %&gt;%\n  filter(`Fuel type` == \"Diesel\", age &lt; 10)\n\nQuestion: How many diesel cars are less than 10 years old?\nYour answer: 2040"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#basic-summaries",
    "href": "labs/lab_0/lab0_template.html#basic-summaries",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "5.1 Basic Summaries",
    "text": "5.1 Basic Summaries\n\n# Calculate average price by manufacturer\navg_price_by_brand &lt;- car_data %&gt;%\n  group_by(Manufacturer) %&gt;%\n  summarize(avg_price = mean(Price, na.rm = TRUE))\n\navg_price_by_brand\n\n# A tibble: 5 × 2\n  Manufacturer avg_price\n  &lt;chr&gt;            &lt;dbl&gt;\n1 BMW             24429.\n2 Ford            10672.\n3 Porsche         29104.\n4 Toyota          14340.\n5 VW              10363.\n\n# Calculate average mileage by fuel type\navg_mileage_by_fuel &lt;- car_df %&gt;%\n  group_by(`Fuel type`) %&gt;%\n  summarize(avg_mileage = mean(Mileage, na.rm = TRUE))\n\navg_mileage_by_fuel\n\n# A tibble: 3 × 2\n  `Fuel type` avg_mileage\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Diesel          112667.\n2 Hybrid          111622.\n3 Petrol          112795.\n\n# Count cars by manufacturer\ncount_by_manufacturer &lt;- car_df %&gt;%\n  group_by(Manufacturer) %&gt;%\n  summarize(car_count = n())\n\ncount_by_manufacturer\n\n# A tibble: 5 × 2\n  Manufacturer car_count\n  &lt;chr&gt;            &lt;int&gt;\n1 BMW               4965\n2 Ford             14959\n3 Porsche           2609\n4 Toyota           12554\n5 VW               14913"
  },
  {
    "objectID": "labs/lab_0/lab0_template.html#categorical-summaries",
    "href": "labs/lab_0/lab0_template.html#categorical-summaries",
    "title": "Lab 0: Getting Started with dplyr",
    "section": "5.2 Categorical Summaries",
    "text": "5.2 Categorical Summaries\n\n# Frequency table for price categories\ncar_df %&gt;%\n  count(price_category)\n\n  price_category     n\n1         budget 34040\n2       midrange  9782\n3        premium  6178"
  }
]